{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing LGPT Bayesian Model to the Basic Frequentist Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-50,50,size = [1000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.sin(x) /x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6b758de4d0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = torch.tensor(np.concatenate( (x,y) ,axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.uniform(-50,50,size = [100,1])\n",
    "y_test = np.sin(x_test) / x_test\n",
    "\n",
    "test_np = torch.tensor(np.concatenate((x_test,y_test),axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the samples after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load('Samples2.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 7 seems to do the job, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_samples = [ samples[7][i][0][0][4][0] for i in range(100000) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing first 80,000 samples as *Burn-In*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6b72fd6190>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5yU1b3H8c9vO70uHaRIEZG6YkURELGiscRcrjWGq9HcxKhRxNjQaPQmJsZKNJaoMVGT6FX0gr1QBJSmAlIFKS69rLts+d0/5tlhdne2wMzubPm+X6958TznnGfmt7PL/OY553nOMXdHREQatqREByAiIomnZCAiIkoGIiKiZCAiIigZiIgIkJLoAA5G27ZtvXv37okOQ0SkTpk/f/4Wd8+MVlcnk0H37t2ZN29eosMQEalTzGxteXXqJhIRESUDERFRMhAREZQMREQEJQMREUHJQEREUDIQERGUDEREaqVte/fx33/7nG1799XI69XJm85EROqLeWu20a1NY1KTkhgyZQYAJ/dvz4wvNwOw4/t8nr18eLXHoWQgIpIg7s55j82iU4sMOrTICJcXJwKAD5dnc/itb3FMr7Y8cUlWtcWiZCAikiB79xUCsGFnLht25lbY7u2vNpdbHw8aMxARSZDzHp1Zpmz5XaeGtw/v1LzGYonpzMDM7gfOBPYBK4HL3H2HmXUHvgKWBU1nu/uVUY5vDfwd6A6sAS5w9+2xxCQiUlcs3bS7TFlaShIv/OQosnfn0b1NE8Y//Em4bmdOPo3Tk0lNjv/3+FifcQYwwN0HAsuBSRF1K919cPAokwgCNwHvuHtv4J1gX0Sk3lrx3Z4SYwLRHNurLeMHd6ZFo9QS5YPunM4nK7ZUS1wxnRm4+/SI3dnAeQf4FOOBkcH2M8D7wI2xxCQiUtvsys1n4O3TGdS1JQvX7ShR17NtE969fiQ5+wponFbyI7lV47QS+2MOa0evzKbVEmM8B5AvJ9TlU6yHmX0O7AJucfePohzT3t03Arj7RjNrV96Tm9lEYCJAt27d4he1iEg1KCpybnvtCy4c3pXTH/wYoEwiAFi1ZS9AmUQA0KJxKq9dcxy5+UW8/dVmJp3aDzOrlngrTQZm9jbQIUrVZHd/NWgzGSgAng/qNgLd3H2rmQ0D/m1mh7v7roMN1N2nAlMBsrKy/GCfR0SkJmzalctfZ6/lr7OjryfTM7MJq7L3MqRbywqfZ2CXUP3wHq3jHmOkSpOBu4+pqN7MLgHOAEa7uwfH5AF5wfZ8M1sJ9AFKL0+22cw6BmcFHYHvDuJnEBGpdR56b0WZsleuOoZzH50FwIxrT2TrnjxaNE4t0y4RYr2aaByhPv4T3T0nojwT2ObuhWbWE+gNrIryFK8BlwD3Bv++Gks8IiK1xQtzvilTNuyQ1tx+Zn86t2pMcpLRrnlGlCMTI9ariR4CmgEzzGyBmT0WlJ8ALDKzhcDLwJXuvg3AzJ4ws+Lb6O4FTjazr4GTg30RkXrj3etOBGDK2QMAuPS4Hpzcv30iQ4oq1quJDi2n/BXglXLqrojY3gqMjiUGEZHaYl9BET95dh7Xje0TLuuZ2ZQ1956ewKiqRtNRiIjEyf8u3MAHy7PZuPN7OrdsRKeWtacbqDJKBiIicXLdSwsBWL55DwDf7vg+keEcEM1NJCJSTTq3bJToEKpMyUBE5CB8tyuX4Gp6IDRe0LX1/g//gV1a8E4weFwXqJtIRKSKVm/ZS/c2jZm7ZjsXPD6Lu88ZwISjDuG+t5by2AcrKXJo2zSd928YSdP0uvXxqjMDEZEq+HT1Nk76n/f5x7x1XPB46MaxD5Zls2VPHo+8H0oEAFv25NW5RABKBiIiVbJsc2i66X99/m2J8numLS2x/5tzjqixmOKp7qUvEZEE2LQzdGXQ7FXbwmXbc/YxPZiO+qlLj+SkfuXOtVnr6cxARKQKFq3fWaZs7pr9a3HV5UQASgYiIlXy0dehRWVm3jSqTtxRfKCUDEREDkCn4N6B3u32LzJzzpDOiQonbjRmICJSie/3FQJw4ZFdw2Uzfll37iGoCp0ZiIhU4tUFoSuIPl29rZKWdZfODEREIqzZspeR//M+Pds24ZwhnVm2eTerskNLU/bt0CzB0VUfJQMREWBPXgFN01O4/X+/AEJrE/9uxvISbW4+7bBEhFYj1E0kIg3eW0s2MeC2/2Px+p28vyy73HZtm6bXYFQ1S8lARBq8xz9cCcA7S0M3kDVLT2HqRcPC9S2DdYobpSXXfHA1RN1EItLgff7NDgD+8PbXAOzOK2B4j9YAXHdyH342unfCYqspMSUDM7sfOBPYB6wELnP3HWY2AbghoulAYKi7Lyh1/O3AT4Di87Kb3X1aLDGJiMRDy8ZprL7nNMws0aHUiFi7iWYAA9x9ILAcmATg7s+7+2B3HwxcBKwpnQgiPFDcVolARGpazr6C8PbZgzsBcM8PQpPNNZREADGeGbj79Ijd2cB5UZr9CPhbLK8jIlIdcvYV8OHyUMfEtWP68PMxvfn9BYNJSmo4SaBYPMcMLgf+HqX8h8D4Co67xswuBuYB17n79miNzGwiMBGgW7duMYYqIg3d83PWMvlfS8L7+wpDdxk3xEQAVegmMrO3zWxJlMf4iDaTgQLg+VLHHgXkuPsSonsU6AUMBjYCvysvDnef6u5Z7p6VmZlZ+U8mIlKByEQA8LNR9X+QuCKVnhm4+5iK6s3sEuAMYLRHLggaciEVdBG5++aI5/kz8Hpl8YiIxGrZpt0l9i/I6kJGav29bLQqYhpANrNxwI3AWe6eU6ouCTgfeLGC4ztG7J4DlHcGISICwLptOUz/YlNMz7Enr6DE/l1n183VyeIp1quJHgKaATPMbIGZPRZRdwKw3t1XRR5gZk+YWVawe5+ZLTazRcBJwLUxxiMi9dyI+95j4l/nU7YjomIXPTmHZ2etAWD55v1nBkvuOIW0FN1/G+vVRIdWUPc+cHSU8isiti+K5fVFpOE64f73WLfte+75wRH8aHjFF5Xc8b9f8NHXW/jo6y18tXEXf/t0HQALbj25Ti5eXx2UDkWkzthXUBTeXrcttCbxpH8uJje/sES7wiJn085cAM5++BOe+mRNuK44EaSlJNGycVo1R1x3KBmISJ3xzbacqOX9fv0Wn32z/6r0XjdP4+h73iF7dx4L1oWmmhjYpUW4vkurRnxww8hqjbWuUTIQkVovN7+QrXvy2LgzdDbw6IShZdp8uWFXmbKj73knvP3j43uEtz++cRQdWzSqhkjrLiUDEan1Jjwxh2F3vc3GoOtnQOcW9AsWmvl08mjMQovS7MrNp6Bwf1dSYVFokPm4Q9twyuEdGNk3k5k3jar5H6AO0MiJiNR689eGuoB+9fIiAJplpPCvnx7Hyuw9tGuWQeeWjXji49U88fFqrh3Tp8zxYw5rT0ZqMk9fNrxG465LdGYgInVOk/QUGqUlM6BzaBygTZP9A8EPvB1aney+cwdybK82AFx2XI+yTyIl6MxARGq1zbtyS+xfflwPUpNLfo9tlpFa5rg+HZrxwk+OPuD7ERoqJQMRqdVeXfBtePvlK48hq3vrMm32BtNQj+rXjneXfgfAYR1DYwoNaRrqWCgZiEit8ubijazM3sOZgzqxde8+GqWFPqZm3jSKTi2jXwF0xsBOfP7NDgZ2acGOnH189s0O0lMa9lxDB8rq4ilUVlaWz5s3L9FhiEgl8guLMCAlufzhyd/PWM7arXv544VD+O+/fc5rCzeUaZOWnMTSKePKnV66qMhZvXUvvTKbUlBYRJGjKSaiMLP57p4VrU5nBiJSLdydQXdMp0PzDN69fmS57R58J7TucFpyUtREALCvsKjCdQaSkoxemU2BihOPlE/JQESqRZ9b3iS/0Fm1ZW+V2r80f301RyQVUTIQkWqRX1h+F/Q3W3PYujePId1alak7oU9meCnK84d1oWPLRhzVo+ygscSXkoGIxF3xh3l5Trj/vXLrpl40jAdmLOfxD1dx5/gBNErTQHBNUOeaiMTVy/PX81apxWdOf/Cj8IyjxVNElCcjNZkbTunL3MljlAhqkM4MRCSurn9pYXi7WXoKu/MK+GLDLt5cspHxgzvz8vx1ZY754o5T+HjFFrq3aQKEBoEzm6XXWMyiMwMRiaO9pZaT/MOFg8PbP39xATtz8rnxlcVljmuSnsIph3egbzD5nNQ8JQMRiZt/R9wt/OiEoYw+rD0LbxsbLht05/Tw9lOXHlmjsUnFYk4GZjbFzBYFayBPN7NOQbmZ2YNmtiKoLzsBeajdsGAd5BVBe907LlJHLd0YWlv4kmMO4dQjOgLQPCN6b/RJ/drx6IShvPWLETUWn5QvHmcG97v7QHcfDLwO3BqUnwr0Dh4TgUfLOf7RoL647bg4xCQiCZC9Ow+An43uHS4zM44/tG2Jdq0ahyaWO/WIjvTr0LzmApRyxTyA7O6Ryws1AYovFRgPPOuh+S5mm1lLM+vo7huLG5tZR6C5u88K9p8FzgbejDUuEal5ycFdwpFTSgM8d8VRPDd7Ld3bNGFPXgGjD2uXiPCkAnG5msjM7gYuBnYCJwXFnYHIywbWB2UbI8o6B+Wl20R7jYmEziDo1q1bPMIWkThZsG4H6SlJvLE49N87Wm/vfx59SE2HJQegSt1EZva2mS2J8hgP4O6T3b0r8DxwTfFhUZ6q9AXGVWlD8BpT3T3L3bMyMzOrEraI1ICdOfmc/fAnnPrHjxIdisSgSmcG7j6mis/3AvAGcBuhb/ldI+q6AKVnoVoflFfURkRqGXdn/MOfsGj9zkSHInESj6uJekfsngUsDbZfAy4Orio6GtgZOV4AEOzvNrOjg6uILgZejTUmEake2/fuI6+gkCufm19uIrhI3UF1UjzGDO41s75AEbAWuDIonwacBqwAcoDLig8wswXB1UcAVwFPA40IDRxr8FiklhoyZQYjerflo6+3lKn704+G8OHybK4a2SsBkUms4nE10bnllDtwdTl1gyO25wEDYo1DRKrXm8HgcGQiWHT7WB56dwXLN+/mzEGdOHNQp0SFJzHS3EQiUiV3vfFVmbLmGancfNphCYhG4k3TUYhIlXy74/sS+91aN05QJFIdlAxEBHfnvreWsmzT7jLlxVKTQ1eCz540mhtO6cu7151YozFK9VIyEBG25+TzyPsrufgvc3B3PvtmOxf/5VN6TJrG7tx8ANo0SWd499Z0aJHB1ScdqrWG6xmNGYgIK77bA8DmXXn0mDStRN0Rt0+nZ2YTNu3K1RTT9ZhSu4hwweOzKqxflR1a1L5Ty0Y1EY4kgM4MRCSqxbeP5YjbQ+sPXHdyHxqlJWt+oXpMZwYiwrG92pDZLJ0xEbOJNstIJeuQVgBcM+pQrhjRk4xUrUlcX+nMQETYvCuXrENacfc5RzD+4Y+5/7xBALx81bEJjkxqipKBSAPn7mzcmcuJfdrRukkaH/1qVKJDkgRQN5FIA7crt4CcfYV0apmR6FAkgZQMRBq4Z2auAaBt0/TEBiIJpWQg0oDtySvg9zOWA9A4TYPDDZnGDEQaoHXbcliRvYfLnpobLhtzWPsERiSJpmQgUg/lFRRyy7+WMOHoQ2iankJufiH9OjQLTyHxq5cXMWvV1nD7ebeMISkp2iq00lAoGYjUQ8/N/oaX5q/npfnrw2VXn9SLG07px968ghKJYHS/dhovEI0ZiNRHU17/skzZw++tZPH6nRx+2/+VKL9j/OE1FZbUYkoGIvXY6QM7ltg/86GPy7Tp0krrEkiM3URmNgUYT2j94++AS919g5lNAG4Mmu0BrnL3hVGOfxo4ESheWftSd18QS0wiDV1h0f41CHq3axq1zRXH92Dy6YdhpnECCYn1zOB+dx8YrGn8OnBrUL4aONHdBwJTgKkVPMcN7j44eCgRiFRi5ootdL/pDZZu2lWm7v++2MTVz38GwM2nhcYHojlnaGclAikhpjMDd4/8a2wCeFA+M6J8NtAlltcRkf3+44k5AIz7w0f8++rjGNy1JQC/n7GcB9/5OtyuaXoqFx/TnbZN07n8+B4kmbFg3XZ6ZTalZeO0hMQutVfMYwZmdreZrQMmsP/MINKPgTcreIq7zWyRmT1gZrqkQeQAvLFoAwCL1+8skQgAfjC0MxmpyfzXib1ITU4iOckYdkhrJQKJyiLXOI3awOxtoEOUqsnu/mpEu0lAhrvfFlF2EvAIcLy7by39BGbWEdgEpBHqSlrp7neWE8dEYCJAt27dhq1du7aSH02k/skvLKL35NB3q2YZKezOLdsN9OrVx3FE5xa6b0DKMLP57p4Vra7SMwN3H+PuA6I8Xi3V9AXg3IgXHQg8AYyPlgiC597oIXnAU8DwCuKY6u5Z7p6VmZlZWdgi9dLGHbkA3HHW4VETAcCgri2VCOSAxdRNZGa9I3bPApYG5d2AfwIXufvyCo7vGPxrwNnAkljiEanvFn8buvBu1/f5CY5E6ptYxwzuNbMlZrYIGAv8PCi/FWgDPGJmC8xsXvEBZjbNzDoFu8+b2WJgMdAWuCvGeETqtblrtgFQ6M6nN48GYPq1J7Dg1pMBOKGPzprl4FQ6ZlAbZWVl+bx58ypvKFLP9Pv1m+TmF7HwtrG0aJRaom71lr10btmItBTdSyrRVTRmoLmJROqQ3PwiAJpnlP2v26Ntk5oOR+oRfYUQqaXcnV25+8cG8guLwtu6YUziTWcGIrXU+Y/NYt7a7fRp35QnLzmSEfe9l+iQpB7TmYFILVJU5Hy9eTcA89ZuB2D55j0lEsHSKeMSEpvUbzozEKlFprzxJU99soafj+4dtX7mTaPISNXylBJ/OjMQqSWKipynPlkDwB9LTS1RrEPzjBqMSBoSJQORBCssctZty+GGlxeVqWuclsylx3YHoGl6iu4slmqjbiKRBPvNtK948uPVUesO69icn4/uzQfLs3nsP4fVcGTSkCgZiCTY6i17S+wf2b0Vc9eEBo9f+q9jSEoy3rt+ZAIik4ZEyUAkwd5d+l14u2l6Cn/98VEs27SbuWu2qVtIaoySgUgCRS5Ruebe08Pbg7q2ZFCwaI1ITdAAskgCFc8++tORvRIciTR0SgYiCbQyew8QGigWSSQlA5EEWpUdGjzu1rpxgiORhk7JQCRB3J1fvRK6t6CgqO5NJS/1iwaQRWrYvoIi+tzyZomyod00WCyJpTMDkRqy4rs9XPTkHHZ8v69MnaaklkTTmYFIDTn/sZlsz8ln+N3vhMsGdWnBMb3aJjAqkZCYk4GZTQHGA0XAd8Cl7r7BzEYCrwLF99n/093vjHJ8D+BFoDXwGXCRu5f96iRSx23PKbmI/VmDOvHgj4YkKBqRkuLRTXS/uw9098HA68CtEXUfufvg4FEmEQR+Czzg7r2B7cCP4xCTSK3XpVWjRIcgEhZzMnD3XRG7TYAqXxZhoY7SUcDLQdEzwNmxxiRSWyz5didXPDOX7N15ZequPunQBEQkEl1cxgzM7G7gYmAncFJE1TFmthDYAFzv7l+UOrQNsMPdC4L99UDneMQkUhuc8aePAcj9+wIgdHPZtWN6s2XPPpqka8hOao8q/TWa2dtAhyhVk939VXefDEw2s0nANcBthPr/D3H3PWZ2GvBvoPTyTdEuoYh6ZmFmE4GJAN26datK2CIJ179jc77cuIuPV2wB4A8/HEzfDs0SHJVIWVXqJnL3Me4+IMrj1VJNXwDODY7Z5e57gu1pQKqZlb5sYgvQ0syKk1IXQmcR0WKY6u5Z7p6VmZlZxR9PJLF25JS8FqJV49QERSJSsZjHDMws8tv+WcDSoLxDMCaAmQ0PXmtr5LHu7sB7wHlB0SWErkASqVNy9hVw7d8XcN0/FpKbXxgu37Azl5SIaahbNUlLRHgilYpHp+W9ZtaX0KWla4Erg/LzgKvMrAD4Hrgw+PDHzKYBV7j7BuBG4EUzuwv4HHgyDjGJVLubXlnEi3PXsebe0zn1jx+xdmsOAGcO6sjIvu1Y8u1OAJo3SuWzX5+cyFBFKhVzMnD3c8spfwh4qJy60yK2VwHDY41DpCblFRTy4tx1ADz+wcpwIgBYtmk3j3+wilmrQifCN47rm5AYRQ6ELmcQOQiRdxHf8+bSEnWl9085PNq1FyK1i+YmEjkAeQWFbN+7j53f55ep+9W4vjTPKPv9qmVjjRNI7adkIBLIzS8kryA0+Ovu3PTKIrrf9AaL1+8Mt7n0L3MZMmVGeD+zWXp4+5iebdiVW4BIXaRkIA3alNe/5LnZawHo9+u3mPDnOewrKKLHpGnhMYFXPlsfbl88DlDsvetHhrdbNNp/2ejhnZqz5t7TS6xrLFKbKRlIg7V6y16e/Hg1t/x7Cf8IPvjnrd3Ora8uKdHu9UUbKSryMlNKXHpsd5pG3EXcqWUjpl97AgD/+K9jqjl6kfiy4GrPOiUrK8vnzZuX6DCkjnvk/RXc99aygzr2B0M6c8sZ/WndJI2CwiKSk0xrEkitZ2bz3T0rWp3ODKTBqiwR/M/5g6KWv/nzEfz+h4NpHdxAlpKcpEQgdZ6SgTRYYw5rX6YsckD4nCGd+fPFoS9Rk07tFy7vp7mFpB7SfQbSIBQVOWYll5dMSTJ6ZjZhVfbecNmnN4+mx6RpACQnGSf3bx8eBM7enccJfTJ1FiD1kpKB1Hv5hUX0nhxagH7iCT05vFNzlm/ezVtfbOKkvpk8cXEWo373AT/M6oqZseo3p5GUVPYD/5Yz+td06CI1RslA6r2rnpsf3p764aoSdd1aN6ZnZtMSl4BGSwQi9Z3GDKTee/ur78qta9c8owYjEam9lAyk3jt7cCcAnr18/3yI14/tw4DOzTn9iI6JCkukVlE3kdRb90z7io4tMvj3gg1kpCYxvEfrcN01o3pzzajSC++JNFxKBlIvPTNzDY9HjA/k5heRkZrMl3eeQmFR3bvRUqS6KRlIvbN00y5ue+2LqHWN0/QnLxKN/mdIvXLcve/y7Y7vy5Qvvn1sAqIRqTuUDKTemPL6l2USwaxJo9idW0CzDC1EL1KRmK4mMrMpZrbIzBaY2XQz6xSU3xCULTCzJWZWaGatoxz/tJmtjmg7OJZ4pGF78uPVJfa7t2lMxxaN6NNe00eIVCbWS0vvd/eB7j4YeB24FcDd73f3wUH5JOADd99WznPcUNzW3RfEGI80UJErj/323CMAuOiY7gmKRqTuiambyN13Rew2AaJdpvEj4G+xvI5IRfIKChl0x/Tw/gVZXTm2V1u6tGqUwKhE6paYbzozs7vNbB0wgeDMIKKuMTAOeKWCp7g76Gp6wMzSK2gnElXfW94qsW9mdG3dWBPKiRyASpOBmb0d9PuXfowHcPfJ7t4VeB64ptThZwKfVNBFNAnoBxwJtAZurCCOiWY2z8zmZWdnV+FHk4ZgX0FRif0PbhiZmEBE6rhKu4ncfUwVn+sF4A3gtoiyC6mgi8jdNwabeWb2FHB9BW2nAlMhtNJZFWOSeu63by0FYFS/dvzl0iMTHI1I3RXr1USR9/OfBSyNqGsBnAi8WsHxHYN/DTgbWFJeW5Foiq8gaq8J50RiEut9BveaWV+gCFgLXBlRdw4w3d33Rh5gZtOAK9x9A/C8mWUCBiwodbxIuVZ8t5tOLfcPEF9y7CEJjEak7ov1aqJzK6h7Gng6SvlpEdujYnl9aZj2FRQx5vcfhveTDPp1aJ7AiETqPk1hLXXO72aUXMhe886JxE7JQOqcxz8ouVpZ8wzNqiISKyUDqXMO6xjqEuqV2QSAf/702ESGI1Iv6CuV1Hp78grYvCuXXplNKSpy2jZNo3FaMu9cNzLRoYnUG0oGUusNuO3/ALj02O48PXMNEJqETkTiR91EUqvlFRSGt4sTAUCXVkoGIvGkZCC1Vs6+gjLzDhVr0UjrE4jEk5KB1FqPvLeyTNl95w4kLTmJC4d3TUBEIvWXkoHUOht2fM++giIeem8FAPefNzBcd8GRXflqyjhG9M5MVHgi9ZIGkCUh3J3n5nzDX2et4clLjqRr69AYwMwVW/iPJ+aUaHvmoE6M7NuOpumhP9fkJE1NLRJvSgaSED0mTQtvj7jvPdbcezpAmUQAkJGaTEZqco3FJtIQqZtIaszWPXm8/eVm3CufP+LeH4SWrkxN1lmASE3QmYHUmGF3vV1u3fG/fZcmafv/HH94ZFeO7NGa7m2a1ERoIg2ekoEkVGazdLJ357F++/fhsguP7IqZ0SuzaQIjE2lY1E0kNSYtJYkebUt+0x/WrVWZdh99vaWmQhKRgM4MpFrNWbWVJRt20alFBvsKijhzUCeuHdObvIIi0lOSWL1lL299sQmAEb3b8tHXW3h4wtAERy3S8CgZSLX64dTZJfY7NM/AzMJXB3Vr3ZhWjVOZeEIvrhrZKxEhighKBlLDcvYVlNhPSU5i7uQxpCSrx1IkkeL2P9DMrjczN7O2wb6Z2YNmtsLMFplZ1HN/MxtmZouDdg+ama4lrAcKCouYv3Z7eP/Gcf04dUAHLj6me5m2SgQiiReXMwMz6wqcDHwTUXwq0Dt4HAU8Gvxb2qPARGA2MA0YB7wZj7iken24PJvXFm7grrMHhLt95q/dTvbuXG5/7Us27coFQolAXUAitVu8uokeAH4FvBpRNh541kN3GM02s5Zm1tHdNxY3MLOOQHN3nxXsPwucjZJBnXDxXz4FIDe/kLSUJLJ350W9Eujk/u1qOjQROUAxJwMzOwv41t0Xlurh6Qysi9hfH5RtLNVmfZQ2Uo68gkJOeeBD1mzN4cIju3LxMd1p3SSNzGbpCZuz5/VFGyus79lW9wuI1HZVSgZm9jbQIUrVZOBmYGy0w6KUlZ6HoCptimOYSKg7iW7dupUba30XOb//i3PX8eLc/fn281+fTKsmaTUSx/LNuyusb5qewvRrT2DTrlySNLGcSK1XpZE7dx/j7gNKP4BVQA9goZmtAboAn5lZB0Lf8iMnne8CbCj11OuD8oraFMcw1d2z3D0rM7PuTl+cm19Ypbl5Ir0yfz0vzPmGwqKSx6WllPz1PfL+ipjjq8zi9Tu54pm5jH3gQwCe+3HJYaA/X5wFQJJBp5aNGBrlpjIRqX1i6iZy98VAuEM4SAhZ7r7FzF4DrjGzFwkNHMt68bYAAA21SURBVO+MHC8Ijt9oZrvN7GhgDnAx8KdYYqrNbn11Cc/OWgvAfecN5KxBncrMxunu/PIfC2nVOI1bz+xPUZFz3UsLAbj5X4tLtN1XUFRiPzc/tL95Vy5H/eYdfjKiBy0bp7F8827+eOGQA4p15/f5bNjxPWkpScz4cjNDurbkkfdX8sHy7BLtju7ZusT+6H7t+PUZ/Tl3qHr7ROoSO9BvqRU+WclkYMBDhK4OygEuc/d5QbsF7j442M4CngYaERo4/plXElRWVpbPmzcvbnHXlO43vVGmbGTfTN5fls2CW0+mRaNUduTkM2TKjHKf44yBHfnFmD7k7CvgrIc+KVP//BVHMSHKNNAArRqn8vmtY/nzh6sY0act/To0L/d1htw5ne05+eXGUDxOsObe05n0z0X87dN1TL/2BPq0b1buc4pIYpnZfHfPiloXz2RQU+piMpi/dhvnPjrroI49snsr5q4JXbO/+p7TKB6oX/Hdbi59ai6vXn1chTOCRlp421gG3TEdCCWipy8bHq6buWIL05Zs5M6zBtDz5mnlPQWnDujAo/85DHdHt4WI1B0VJQPd7VON8goK+XZHaDbO4kQwqGtLvrpzXKXH3nBK3/D2M5cP56xBnTh/WJcSH76HtmvGxzeOok3TdH53/qCoz3NUj5LdOOc+OjO8/f6ybN5asr/n7j+emMNzs79h1qqtAIzqt/+S0FaN9y9AX1yvRCBSfygZVKO+t7zFcfe+y67c/d0tt57Rn0ZpySy+fSxf3HFKucf+NOImrfSUZB780RDuL+cDH2BEn7bh7T/9aP/4wBUjepZot+K7PaHy43sAcOVzn/HFhp3k5heG2xR3M43sm8mN4/oB8NtzB4bHB64b2xcRqV+UDOJkV24+90z7iu+Cu24jDbx9enh72CGhq2uaZaTSJD2lREL4n+DD/r7zBmJmjO7XjlaNU6t0/0C7Zhnh7VMO78CnN4/m2cuHc3L/9rx85TF8Onk0c24eHW5zXtb+i7hOf/Bj+v36LUrLzS/kqpG9WHbXOMYe3oGfjeoNwNj+7SuNR0TqFk1UFyfFH/iPf7iKz359MnkFhWXa3H5m/zJlTdL3/wrOG9aF0f3a0TLoknny0iMPKIbfnT+Ildl7SEtJol3zDNo1DyWIrO6ty7Q9tJyFYy48smv43oVzhoQSRnpK6Iqn4w5tG16rWETqFyWDajA0ytVAy+4aF/5QLW3qRcPIDS4TjeWmsXOHdam0zbT/HgGEJoc7a1AnXlu4gdd/djxn/OljAH4xpg/3njvwoGMQkbpJySAONu0s2zVUWnmJAGDs4dFu7q4e/Tvtv5z0gR8O5oZT+tK1dWN+d/4gUlOS6NAio4KjRaS+0phBHKzesheAlFJ9+zNvGpWIcKosOcno2roxEDqrOGtQpwRHJCKJojODGC3btDs8DcTDE4aSs6+Aa/8eumO4U8tGvP6z42tsviARkYOlZBCD1xdt4JoXPg/vZzZLZ0jX9rwy/1suHB6almlA5xaJCk9EpMqUDGIQmQiA8KRsz10RbQ0fEZHaS8ngIGXvzgtvt2+eTvOM1Apai4jUbkoG5TjzTx/jOK//bETU+iPv3j8X0OxJo6O2ERGpK3Q1UYR123KY8vqXrN26l8Xf7mTJt7tYvz2nwmMemTAUM9M8PSJSp+nMIMKI+94D4MmPV4fLPliezelHdGR7Tj492jYBQou+F+vUslHNBikiUg0aZDIoClYMq8pyjMs37eahd1ewcWcuT16SxUdfb+HpmWvC9Ye20/q+IlL3NbhkcPFfPuXDYLWu4nl28goKGfP7DwDISE0KrxgG8EywMhnAj5/Zv4ZC55aNmPbzETRNb3BvoYjUQw1qzKCwyMOJAOC6f4RuDtu8M49120LrDuQXOu9fP5LFt4+tcLbQT24aRYtGuoJIROqHBpUMjvpNydXAXvlsPXvzClgXMUj854uH0b1tE5plpPLwfwyt6RBFRBKiQSWDLXv2lSm74PFZJdYMHtln/+pe4wZ04O5zBgCw/K5TwwvCiIjUN3FJBmZ2vZm5mbUN9ieY2aLgMdPMoi7RZWZPm9lqM1sQPAbHI57yvPHfx9O7XVNW/eY03v7lCQB8sWFXuH7WpFFlBpUnHHUIa+49nbSUJG4+7TBaNEoNr/4lIlJfxDz6aWZdgZOBbyKKVwMnuvt2MzsVmAqUN0fDDe7+cqxxVMXhnVow45cnAtClVeMSddOvPYGOLSq+TDQpyVh429hqi09EJFHicWbwAPArwIsL3H2muxdfjD8bqHzVlRqWnrL/R89slk6f9s0SGI2ISGLFlAzM7CzgW3dfWEGzHwNvVlB/d9Cd9ICZpVfwWhPNbJ6ZzcvOzi6vWZWZGc9cPhyA7XvLjiWIiDQklXYTmdnbQLSluCYDNwPl9puY2UmEksHx5TSZBGwC0gh1Jd0I3BmtobtPDdqQlZXl0docqON6teG/TuzJFcf3jMfTiYjUWZUmA3cfE63czI4AegALg3l5ugCfmdlwd99kZgOBJ4BT3X1rOc+9MdjMM7OngOsP4mc4aCnJSUw69bCafEkRkVrpoAeQ3X0xEL4O08zWAFnuvsXMugH/BC5y9+XlPYeZdXT3jRbKJmcDSw42HhEROXjVNZfCrUAb4JHgrKHA3bMAzGwacIW7bwCeN7NMwIAFwJXVFI+IiFQgbsnA3btHbF8BXFFOu9Mitmv3ivEiIg1Eg7oDWUREolMyEBERJQMREVEyEBERlAxERAQw97jczFujzCwbWFtpw+jaAlviGE68KK4Do7gOjOI6MLU1LogttkPcPTNaRZ1MBrEws3nF9zzUJorrwCiuA6O4DkxtjQuqLzZ1E4mIiJKBiIg0zGQwNdEBlENxHRjFdWAU14GprXFBNcXW4MYMRESkrIZ4ZiAiIqUoGYiISMNKBmY2zsyWmdkKM7upml+rq5m9Z2ZfmdkXZvbzoPx2M/vWzBYEj9MijpkUxLbMzE6pzrjNbI2ZLQ5imBeUtTazGWb2dfBvq6DczOzB4PUXmdnQiOe5JGj/tZldEkM8fSPekwVmtsvMfpGo98vM/mJm35nZkoiyuL0/ZjYseP9XBMdaDHHdb2ZLg9f+l5m1DMq7m9n3Ee/dY5W9fnk/40HGFbffnZn1MLM5QVx/N7O0GOL6e0RMa8xsQQLer/I+HxL3N+buDeIBJAMrgZ6EltlcCPSvxtfrCAwNtpsBy4H+wO3A9VHa9w9iSie0gtzKIOZqiRtYA7QtVXYfcFOwfRPw22D7NELrWBtwNDAnKG8NrAr+bRVst4rT72oTcEii3i/gBGAosKQ63h/gU+CY4Jg3Ca0IeLBxjQVSgu3fRsTVPbJdqeeJ+vrl/YwHGVfcfnfAP4ALg+3HgKsONq5S9b8Dbk3A+1Xe50PC/sYa0pnBcGCFu69y933Ai8D46noxd9/o7p8F27uBr4DOFRwyHnjR3fPcfTWwIoi5JuMeDzwTbD9DaPW54vJnPWQ20NLMOgKnADPcfZu7bwdmAOPiEMdoYKW7V3SXebW+X+7+IbAtymvG/P4Edc3dfZaH/tc+G/FcBxyXu09394JgdzahJWjLVcnrl/czHnBcFTig313wjXYU8HI84wqe9wLgbxU9RzW9X+V9PiTsb6whJYPOwLqI/fVU/OEcN2bWHRgCzAmKrglO9f4ScVpZXnzVFbcD081svplNDMrae7AudfBv8bKmNR3bhZT8D1ob3i+I3/vTOdiujhgvJ/QtsFgPM/vczD4wsxER8Zb3+uX9jAcrHr+7NsCOiIQXr/drBLDZ3b+OKKvx96vU50PC/sYaUjKI1l9W7dfVmllT4BXgF+6+C3gU6AUMBjYSOk2tKL7qivs4dx8KnApcbWYnVNC2xmIL+oLPAl4KimrL+1WRA42lWmI0s8lAAfB8ULQR6ObuQ4BfAi+YWfPqev0o4vW7q654f0TJLx01/n5F+Xwot2k5McTtPWtIyWA90DVivwuwoTpf0MxSCf2in3f3fwK4+2Z3L3T3IuDPhE6NK4qvWuL20BrUuPt3wL+CODYHp5fFp8bfJSC2U4HP3H1zEF+teL8C8Xp/1lOyKyfmGIOBwzOACUG3AEE3zNZgez6h/vg+lbx+eT/jAYvj724LoW6RlFLlBy14rh8Af4+It0bfr2ifDxU8X/X/jVVlsKM+PAit97yK0IBV8eDU4dX4ekaon+4Ppco7RmxfS6jvFOBwSg6qrSI0oBb3uIEmQLOI7ZmE+vrvp+Tg1X3B9umUHLz61PcPXq0mNHDVKthuHWNsLwKX1Yb3i1IDivF8f4C5Qdviwb3TYohrHPAlkFmqXSaQHGz3BL6t7PXL+xkPMq64/e4InSlGDiD/9GDjinjPPkjU+0X5nw8J+xurlg/C2vogNCK/nFDGn1zNr3U8odOyRcCC4HEa8FdgcVD+Wqn/MJOD2JYRMfIf77iDP/SFweOL4uck1Df7DvB18G/xH5UBDwevvxjIiniuywkNAK4g4kP8IONqDGwFWkSUJeT9ItR9sBHIJ/Qt68fxfH+ALGBJcMxDBLMBHGRcKwj1Gxf/nT0WtD03+P0uBD4Dzqzs9cv7GQ8yrrj97oK/2U+Dn/UlIP1g4wrKnwauLNW2Jt+v8j4fEvY3pukoRESkQY0ZiIhIOZQMREREyUBERJQMREQEJQMREUHJQEREUDIQERHg/wHGrNRWmHB7zgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( w1_samples[80000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the final samples\n",
    "\n",
    "### *Note that I took the Mean Aggregator to obtain a pointwise estimate of the Weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samples = [ samples[7][i][0] for i in range(80000,100000) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.concatenate( [final_samples[i][0] for i in range(20000)], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.mean(w1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.concatenate( [np.expand_dims(final_samples[i][1], axis = 1) for i in range(20000)], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = np.mean(b1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = np.concatenate( [np.reshape(final_samples[i][2], [-1,1]) for i in range(20000)], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.mean(w2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = np.concatenate( [np.reshape(final_samples[i][3], [-1,1]) for i in range(20000)], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2 = np.mean(b2, axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalParams = [torch.tensor(W1.reshape(final_samples[0][0].shape)), torch.tensor(B1.reshape(final_samples[0][1].shape)), torch.tensor(W2.reshape(final_samples[0][2].shape)), torch.tensor(B2.reshape(final_samples[0][3].shape))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the same Model and testing it's performace on above weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = torch.nn.Sequential( torch.nn.Linear(1, 5), torch.nn.Sigmoid(), torch.nn.Linear(5, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.load_state_dict( dict(zip(list(Model.state_dict().keys()), FinalParams)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = torch.tensor( np.reshape(np.linspace(-50,50,1000),[-1,1]) ,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = Model(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSELoss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1163, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSELoss(np.sin(xt)/xt , yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss is a bit high, but that's kinda expected with Bayesian Neural Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2, 1.4)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xt,yt.reshape([-1]).detach().numpy())\n",
    "plt.plot(x,y,'bo')\n",
    "plt.ylim([-0.2,1.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a brand new Model for 5000 epochs on same task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = torch.nn.Sequential( torch.nn.Linear(1, 5), torch.nn.Sigmoid(), torch.nn.Linear(5, 1) )\n",
    "optim = torch.optim.SGD(Model.parameters(), lr = 0.001)\n",
    "lossfunc = torch.nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    xtrain = xt\n",
    "    ytrue = np.sin(xt)/xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Loss:  tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1\n",
      "Loss:  tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2\n",
      "Loss:  tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3\n",
      "Loss:  tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4\n",
      "Loss:  tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "Epoch:  5\n",
      "Loss:  tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "Epoch:  6\n",
      "Loss:  tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "Epoch:  7\n",
      "Loss:  tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "Epoch:  8\n",
      "Loss:  tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "Epoch:  9\n",
      "Loss:  tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "Epoch:  10\n",
      "Loss:  tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "Epoch:  11\n",
      "Loss:  tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "Epoch:  12\n",
      "Loss:  tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "Epoch:  13\n",
      "Loss:  tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "Epoch:  14\n",
      "Loss:  tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "Epoch:  15\n",
      "Loss:  tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "Epoch:  16\n",
      "Loss:  tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "Epoch:  17\n",
      "Loss:  tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "Epoch:  18\n",
      "Loss:  tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "Epoch:  19\n",
      "Loss:  tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "Epoch:  20\n",
      "Loss:  tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "Epoch:  21\n",
      "Loss:  tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "Epoch:  22\n",
      "Loss:  tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "Epoch:  23\n",
      "Loss:  tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "Epoch:  24\n",
      "Loss:  tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "Epoch:  25\n",
      "Loss:  tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "Epoch:  26\n",
      "Loss:  tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "Epoch:  27\n",
      "Loss:  tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "Epoch:  28\n",
      "Loss:  tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "Epoch:  29\n",
      "Loss:  tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "Epoch:  30\n",
      "Loss:  tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "Epoch:  31\n",
      "Loss:  tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "Epoch:  32\n",
      "Loss:  tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "Epoch:  33\n",
      "Loss:  tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "Epoch:  34\n",
      "Loss:  tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "Epoch:  35\n",
      "Loss:  tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "Epoch:  36\n",
      "Loss:  tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "Epoch:  37\n",
      "Loss:  tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "Epoch:  38\n",
      "Loss:  tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "Epoch:  39\n",
      "Loss:  tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "Epoch:  40\n",
      "Loss:  tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "Epoch:  41\n",
      "Loss:  tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "Epoch:  42\n",
      "Loss:  tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "Epoch:  43\n",
      "Loss:  tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "Epoch:  44\n",
      "Loss:  tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "Epoch:  45\n",
      "Loss:  tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "Epoch:  46\n",
      "Loss:  tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "Epoch:  47\n",
      "Loss:  tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "Epoch:  48\n",
      "Loss:  tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "Epoch:  49\n",
      "Loss:  tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "Epoch:  50\n",
      "Loss:  tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "Epoch:  51\n",
      "Loss:  tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "Epoch:  52\n",
      "Loss:  tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "Epoch:  53\n",
      "Loss:  tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "Epoch:  54\n",
      "Loss:  tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "Epoch:  55\n",
      "Loss:  tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "Epoch:  56\n",
      "Loss:  tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "Epoch:  57\n",
      "Loss:  tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "Epoch:  58\n",
      "Loss:  tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "Epoch:  59\n",
      "Loss:  tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "Epoch:  60\n",
      "Loss:  tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "Epoch:  61\n",
      "Loss:  tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "Epoch:  62\n",
      "Loss:  tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "Epoch:  63\n",
      "Loss:  tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "Epoch:  64\n",
      "Loss:  tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "Epoch:  65\n",
      "Loss:  tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "Epoch:  66\n",
      "Loss:  tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "Epoch:  67\n",
      "Loss:  tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "Epoch:  68\n",
      "Loss:  tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "Epoch:  69\n",
      "Loss:  tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "Epoch:  70\n",
      "Loss:  tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "Epoch:  71\n",
      "Loss:  tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "Epoch:  72\n",
      "Loss:  tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "Epoch:  73\n",
      "Loss:  tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "Epoch:  74\n",
      "Loss:  tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "Epoch:  75\n",
      "Loss:  tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "Epoch:  76\n",
      "Loss:  tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "Epoch:  77\n",
      "Loss:  tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "Epoch:  78\n",
      "Loss:  tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "Epoch:  79\n",
      "Loss:  tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "Epoch:  80\n",
      "Loss:  tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "Epoch:  81\n",
      "Loss:  tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "Epoch:  82\n",
      "Loss:  tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "Epoch:  83\n",
      "Loss:  tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "Epoch:  84\n",
      "Loss:  tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "Epoch:  85\n",
      "Loss:  tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "Epoch:  86\n",
      "Loss:  tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "Epoch:  87\n",
      "Loss:  tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "Epoch:  88\n",
      "Loss:  tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "Epoch:  89\n",
      "Loss:  tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "Epoch:  90\n",
      "Loss:  tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "Epoch:  91\n",
      "Loss:  tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "Epoch:  92\n",
      "Loss:  tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "Epoch:  93\n",
      "Loss:  tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "Epoch:  94\n",
      "Loss:  tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "Epoch:  95\n",
      "Loss:  tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "Epoch:  96\n",
      "Loss:  tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "Epoch:  97\n",
      "Loss:  tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "Epoch:  98\n",
      "Loss:  tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "Epoch:  99\n",
      "Loss:  tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "Epoch:  100\n",
      "Loss:  tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "Epoch:  101\n",
      "Loss:  tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "Epoch:  102\n",
      "Loss:  tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "Epoch:  103\n",
      "Loss:  tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "Epoch:  104\n",
      "Loss:  tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "Epoch:  105\n",
      "Loss:  tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "Epoch:  106\n",
      "Loss:  tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "Epoch:  107\n",
      "Loss:  tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "Epoch:  108\n",
      "Loss:  tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "Epoch:  109\n",
      "Loss:  tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "Epoch:  110\n",
      "Loss:  tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "Epoch:  111\n",
      "Loss:  tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "Epoch:  112\n",
      "Loss:  tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "Epoch:  113\n",
      "Loss:  tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "Epoch:  114\n",
      "Loss:  tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "Epoch:  115\n",
      "Loss:  tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "Epoch:  116\n",
      "Loss:  tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "Epoch:  117\n",
      "Loss:  tensor(0.0548, grad_fn=<MeanBackward0>)\n",
      "Epoch:  118\n",
      "Loss:  tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "Epoch:  119\n",
      "Loss:  tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "Epoch:  120\n",
      "Loss:  tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "Epoch:  121\n",
      "Loss:  tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "Epoch:  122\n",
      "Loss:  tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "Epoch:  123\n",
      "Loss:  tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "Epoch:  124\n",
      "Loss:  tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "Epoch:  125\n",
      "Loss:  tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "Epoch:  126\n",
      "Loss:  tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "Epoch:  127\n",
      "Loss:  tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "Epoch:  128\n",
      "Loss:  tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "Epoch:  129\n",
      "Loss:  tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "Epoch:  130\n",
      "Loss:  tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "Epoch:  131\n",
      "Loss:  tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "Epoch:  132\n",
      "Loss:  tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "Epoch:  133\n",
      "Loss:  tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "Epoch:  134\n",
      "Loss:  tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "Epoch:  135\n",
      "Loss:  tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "Epoch:  136\n",
      "Loss:  tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "Epoch:  137\n",
      "Loss:  tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "Epoch:  138\n",
      "Loss:  tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "Epoch:  139\n",
      "Loss:  tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "Epoch:  140\n",
      "Loss:  tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "Epoch:  141\n",
      "Loss:  tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "Epoch:  142\n",
      "Loss:  tensor(0.0517, grad_fn=<MeanBackward0>)\n",
      "Epoch:  143\n",
      "Loss:  tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "Epoch:  144\n",
      "Loss:  tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "Epoch:  145\n",
      "Loss:  tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "Epoch:  146\n",
      "Loss:  tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "Epoch:  147\n",
      "Loss:  tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "Epoch:  148\n",
      "Loss:  tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "Epoch:  149\n",
      "Loss:  tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "Epoch:  150\n",
      "Loss:  tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "Epoch:  151\n",
      "Loss:  tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "Epoch:  152\n",
      "Loss:  tensor(0.0506, grad_fn=<MeanBackward0>)\n",
      "Epoch:  153\n",
      "Loss:  tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "Epoch:  154\n",
      "Loss:  tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "Epoch:  155\n",
      "Loss:  tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "Epoch:  156\n",
      "Loss:  tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "Epoch:  157\n",
      "Loss:  tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "Epoch:  158\n",
      "Loss:  tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "Epoch:  159\n",
      "Loss:  tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "Epoch:  160\n",
      "Loss:  tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "Epoch:  161\n",
      "Loss:  tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "Epoch:  162\n",
      "Loss:  tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "Epoch:  163\n",
      "Loss:  tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "Epoch:  164\n",
      "Loss:  tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "Epoch:  165\n",
      "Loss:  tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "Epoch:  166\n",
      "Loss:  tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "Epoch:  167\n",
      "Loss:  tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "Epoch:  168\n",
      "Loss:  tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "Epoch:  169\n",
      "Loss:  tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "Epoch:  170\n",
      "Loss:  tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "Epoch:  171\n",
      "Loss:  tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "Epoch:  172\n",
      "Loss:  tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "Epoch:  173\n",
      "Loss:  tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "Epoch:  174\n",
      "Loss:  tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "Epoch:  175\n",
      "Loss:  tensor(0.0483, grad_fn=<MeanBackward0>)\n",
      "Epoch:  176\n",
      "Loss:  tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "Epoch:  177\n",
      "Loss:  tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "Epoch:  178\n",
      "Loss:  tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "Epoch:  179\n",
      "Loss:  tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "Epoch:  180\n",
      "Loss:  tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "Epoch:  181\n",
      "Loss:  tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "Epoch:  182\n",
      "Loss:  tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "Epoch:  183\n",
      "Loss:  tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "Epoch:  184\n",
      "Loss:  tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "Epoch:  185\n",
      "Loss:  tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "Epoch:  186\n",
      "Loss:  tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "Epoch:  187\n",
      "Loss:  tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "Epoch:  188\n",
      "Loss:  tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "Epoch:  189\n",
      "Loss:  tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "Epoch:  190\n",
      "Loss:  tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "Epoch:  191\n",
      "Loss:  tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "Epoch:  192\n",
      "Loss:  tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "Epoch:  193\n",
      "Loss:  tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "Epoch:  194\n",
      "Loss:  tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "Epoch:  195\n",
      "Loss:  tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "Epoch:  196\n",
      "Loss:  tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "Epoch:  197\n",
      "Loss:  tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "Epoch:  198\n",
      "Loss:  tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "Epoch:  199\n",
      "Loss:  tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "Epoch:  200\n",
      "Loss:  tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "Epoch:  201\n",
      "Loss:  tensor(0.0461, grad_fn=<MeanBackward0>)\n",
      "Epoch:  202\n",
      "Loss:  tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "Epoch:  203\n",
      "Loss:  tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "Epoch:  204\n",
      "Loss:  tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "Epoch:  205\n",
      "Loss:  tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "Epoch:  206\n",
      "Loss:  tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "Epoch:  207\n",
      "Loss:  tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "Epoch:  208\n",
      "Loss:  tensor(0.0456, grad_fn=<MeanBackward0>)\n",
      "Epoch:  209\n",
      "Loss:  tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "Epoch:  210\n",
      "Loss:  tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "Epoch:  211\n",
      "Loss:  tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "Epoch:  212\n",
      "Loss:  tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "Epoch:  213\n",
      "Loss:  tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "Epoch:  214\n",
      "Loss:  tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "Epoch:  215\n",
      "Loss:  tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "Epoch:  216\n",
      "Loss:  tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "Epoch:  217\n",
      "Loss:  tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "Epoch:  218\n",
      "Loss:  tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "Epoch:  219\n",
      "Loss:  tensor(0.0448, grad_fn=<MeanBackward0>)\n",
      "Epoch:  220\n",
      "Loss:  tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "Epoch:  221\n",
      "Loss:  tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "Epoch:  222\n",
      "Loss:  tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "Epoch:  223\n",
      "Loss:  tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "Epoch:  224\n",
      "Loss:  tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "Epoch:  225\n",
      "Loss:  tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "Epoch:  226\n",
      "Loss:  tensor(0.0443, grad_fn=<MeanBackward0>)\n",
      "Epoch:  227\n",
      "Loss:  tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "Epoch:  228\n",
      "Loss:  tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "Epoch:  229\n",
      "Loss:  tensor(0.0441, grad_fn=<MeanBackward0>)\n",
      "Epoch:  230\n",
      "Loss:  tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "Epoch:  231\n",
      "Loss:  tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "Epoch:  232\n",
      "Loss:  tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "Epoch:  233\n",
      "Loss:  tensor(0.0438, grad_fn=<MeanBackward0>)\n",
      "Epoch:  234\n",
      "Loss:  tensor(0.0438, grad_fn=<MeanBackward0>)\n",
      "Epoch:  235\n",
      "Loss:  tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "Epoch:  236\n",
      "Loss:  tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "Epoch:  237\n",
      "Loss:  tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "Epoch:  238\n",
      "Loss:  tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "Epoch:  239\n",
      "Loss:  tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "Epoch:  240\n",
      "Loss:  tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "Epoch:  241\n",
      "Loss:  tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "Epoch:  242\n",
      "Loss:  tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "Epoch:  243\n",
      "Loss:  tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "Epoch:  244\n",
      "Loss:  tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "Epoch:  245\n",
      "Loss:  tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "Epoch:  246\n",
      "Loss:  tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "Epoch:  247\n",
      "Loss:  tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "Epoch:  248\n",
      "Loss:  tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "Epoch:  249\n",
      "Loss:  tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "Epoch:  250\n",
      "Loss:  tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "Epoch:  251\n",
      "Loss:  tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "Epoch:  252\n",
      "Loss:  tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "Epoch:  253\n",
      "Loss:  tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "Epoch:  254\n",
      "Loss:  tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "Epoch:  255\n",
      "Loss:  tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "Epoch:  256\n",
      "Loss:  tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "Epoch:  257\n",
      "Loss:  tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "Epoch:  258\n",
      "Loss:  tensor(0.0423, grad_fn=<MeanBackward0>)\n",
      "Epoch:  259\n",
      "Loss:  tensor(0.0423, grad_fn=<MeanBackward0>)\n",
      "Epoch:  260\n",
      "Loss:  tensor(0.0422, grad_fn=<MeanBackward0>)\n",
      "Epoch:  261\n",
      "Loss:  tensor(0.0422, grad_fn=<MeanBackward0>)\n",
      "Epoch:  262\n",
      "Loss:  tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "Epoch:  263\n",
      "Loss:  tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "Epoch:  264\n",
      "Loss:  tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "Epoch:  265\n",
      "Loss:  tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "Epoch:  266\n",
      "Loss:  tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "Epoch:  267\n",
      "Loss:  tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "Epoch:  268\n",
      "Loss:  tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "Epoch:  269\n",
      "Loss:  tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "Epoch:  270\n",
      "Loss:  tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "Epoch:  271\n",
      "Loss:  tensor(0.0416, grad_fn=<MeanBackward0>)\n",
      "Epoch:  272\n",
      "Loss:  tensor(0.0416, grad_fn=<MeanBackward0>)\n",
      "Epoch:  273\n",
      "Loss:  tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "Epoch:  274\n",
      "Loss:  tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "Epoch:  275\n",
      "Loss:  tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "Epoch:  276\n",
      "Loss:  tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "Epoch:  277\n",
      "Loss:  tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "Epoch:  278\n",
      "Loss:  tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "Epoch:  279\n",
      "Loss:  tensor(0.0412, grad_fn=<MeanBackward0>)\n",
      "Epoch:  280\n",
      "Loss:  tensor(0.0412, grad_fn=<MeanBackward0>)\n",
      "Epoch:  281\n",
      "Loss:  tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "Epoch:  282\n",
      "Loss:  tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "Epoch:  283\n",
      "Loss:  tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "Epoch:  284\n",
      "Loss:  tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "Epoch:  285\n",
      "Loss:  tensor(0.0409, grad_fn=<MeanBackward0>)\n",
      "Epoch:  286\n",
      "Loss:  tensor(0.0409, grad_fn=<MeanBackward0>)\n",
      "Epoch:  287\n",
      "Loss:  tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "Epoch:  288\n",
      "Loss:  tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "Epoch:  289\n",
      "Loss:  tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "Epoch:  290\n",
      "Loss:  tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "Epoch:  291\n",
      "Loss:  tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "Epoch:  292\n",
      "Loss:  tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "Epoch:  293\n",
      "Loss:  tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "Epoch:  294\n",
      "Loss:  tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "Epoch:  295\n",
      "Loss:  tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "Epoch:  296\n",
      "Loss:  tensor(0.0404, grad_fn=<MeanBackward0>)\n",
      "Epoch:  297\n",
      "Loss:  tensor(0.0404, grad_fn=<MeanBackward0>)\n",
      "Epoch:  298\n",
      "Loss:  tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "Epoch:  299\n",
      "Loss:  tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "Epoch:  300\n",
      "Loss:  tensor(0.0402, grad_fn=<MeanBackward0>)\n",
      "Epoch:  301\n",
      "Loss:  tensor(0.0402, grad_fn=<MeanBackward0>)\n",
      "Epoch:  302\n",
      "Loss:  tensor(0.0401, grad_fn=<MeanBackward0>)\n",
      "Epoch:  303\n",
      "Loss:  tensor(0.0401, grad_fn=<MeanBackward0>)\n",
      "Epoch:  304\n",
      "Loss:  tensor(0.0401, grad_fn=<MeanBackward0>)\n",
      "Epoch:  305\n",
      "Loss:  tensor(0.0400, grad_fn=<MeanBackward0>)\n",
      "Epoch:  306\n",
      "Loss:  tensor(0.0400, grad_fn=<MeanBackward0>)\n",
      "Epoch:  307\n",
      "Loss:  tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "Epoch:  308\n",
      "Loss:  tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "Epoch:  309\n",
      "Loss:  tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "Epoch:  310\n",
      "Loss:  tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "Epoch:  311\n",
      "Loss:  tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "Epoch:  312\n",
      "Loss:  tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "Epoch:  313\n",
      "Loss:  tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "Epoch:  314\n",
      "Loss:  tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "Epoch:  315\n",
      "Loss:  tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "Epoch:  316\n",
      "Loss:  tensor(0.0395, grad_fn=<MeanBackward0>)\n",
      "Epoch:  317\n",
      "Loss:  tensor(0.0395, grad_fn=<MeanBackward0>)\n",
      "Epoch:  318\n",
      "Loss:  tensor(0.0395, grad_fn=<MeanBackward0>)\n",
      "Epoch:  319\n",
      "Loss:  tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "Epoch:  320\n",
      "Loss:  tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "Epoch:  321\n",
      "Loss:  tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "Epoch:  322\n",
      "Loss:  tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "Epoch:  323\n",
      "Loss:  tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "Epoch:  324\n",
      "Loss:  tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "Epoch:  325\n",
      "Loss:  tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "Epoch:  326\n",
      "Loss:  tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "Epoch:  327\n",
      "Loss:  tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "Epoch:  328\n",
      "Loss:  tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "Epoch:  329\n",
      "Loss:  tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "Epoch:  330\n",
      "Loss:  tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "Epoch:  331\n",
      "Loss:  tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "Epoch:  332\n",
      "Loss:  tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "Epoch:  333\n",
      "Loss:  tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "Epoch:  334\n",
      "Loss:  tensor(0.0388, grad_fn=<MeanBackward0>)\n",
      "Epoch:  335\n",
      "Loss:  tensor(0.0388, grad_fn=<MeanBackward0>)\n",
      "Epoch:  336\n",
      "Loss:  tensor(0.0388, grad_fn=<MeanBackward0>)\n",
      "Epoch:  337\n",
      "Loss:  tensor(0.0387, grad_fn=<MeanBackward0>)\n",
      "Epoch:  338\n",
      "Loss:  tensor(0.0387, grad_fn=<MeanBackward0>)\n",
      "Epoch:  339\n",
      "Loss:  tensor(0.0387, grad_fn=<MeanBackward0>)\n",
      "Epoch:  340\n",
      "Loss:  tensor(0.0386, grad_fn=<MeanBackward0>)\n",
      "Epoch:  341\n",
      "Loss:  tensor(0.0386, grad_fn=<MeanBackward0>)\n",
      "Epoch:  342\n",
      "Loss:  tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "Epoch:  343\n",
      "Loss:  tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "Epoch:  344\n",
      "Loss:  tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "Epoch:  345\n",
      "Loss:  tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "Epoch:  346\n",
      "Loss:  tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "Epoch:  347\n",
      "Loss:  tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "Epoch:  348\n",
      "Loss:  tensor(0.0383, grad_fn=<MeanBackward0>)\n",
      "Epoch:  349\n",
      "Loss:  tensor(0.0383, grad_fn=<MeanBackward0>)\n",
      "Epoch:  350\n",
      "Loss:  tensor(0.0383, grad_fn=<MeanBackward0>)\n",
      "Epoch:  351\n",
      "Loss:  tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "Epoch:  352\n",
      "Loss:  tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "Epoch:  353\n",
      "Loss:  tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "Epoch:  354\n",
      "Loss:  tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "Epoch:  355\n",
      "Loss:  tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "Epoch:  356\n",
      "Loss:  tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "Epoch:  357\n",
      "Loss:  tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "Epoch:  358\n",
      "Loss:  tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "Epoch:  359\n",
      "Loss:  tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "Epoch:  360\n",
      "Loss:  tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "Epoch:  361\n",
      "Loss:  tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "Epoch:  362\n",
      "Loss:  tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "Epoch:  363\n",
      "Loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "Epoch:  364\n",
      "Loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "Epoch:  365\n",
      "Loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "Epoch:  366\n",
      "Loss:  tensor(0.0377, grad_fn=<MeanBackward0>)\n",
      "Epoch:  367\n",
      "Loss:  tensor(0.0377, grad_fn=<MeanBackward0>)\n",
      "Epoch:  368\n",
      "Loss:  tensor(0.0377, grad_fn=<MeanBackward0>)\n",
      "Epoch:  369\n",
      "Loss:  tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "Epoch:  370\n",
      "Loss:  tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "Epoch:  371\n",
      "Loss:  tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "Epoch:  372\n",
      "Loss:  tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "Epoch:  373\n",
      "Loss:  tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "Epoch:  374\n",
      "Loss:  tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "Epoch:  375\n",
      "Loss:  tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "Epoch:  376\n",
      "Loss:  tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Epoch:  377\n",
      "Loss:  tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Epoch:  378\n",
      "Loss:  tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Epoch:  379\n",
      "Loss:  tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "Epoch:  380\n",
      "Loss:  tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "Epoch:  381\n",
      "Loss:  tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "Epoch:  382\n",
      "Loss:  tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "Epoch:  383\n",
      "Loss:  tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "Epoch:  384\n",
      "Loss:  tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "Epoch:  385\n",
      "Loss:  tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "Epoch:  386\n",
      "Loss:  tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "Epoch:  387\n",
      "Loss:  tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "Epoch:  388\n",
      "Loss:  tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "Epoch:  389\n",
      "Loss:  tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "Epoch:  390\n",
      "Loss:  tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "Epoch:  391\n",
      "Loss:  tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "Epoch:  392\n",
      "Loss:  tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "Epoch:  393\n",
      "Loss:  tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "Epoch:  394\n",
      "Loss:  tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "Epoch:  395\n",
      "Loss:  tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "Epoch:  396\n",
      "Loss:  tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "Epoch:  397\n",
      "Loss:  tensor(0.0368, grad_fn=<MeanBackward0>)\n",
      "Epoch:  398\n",
      "Loss:  tensor(0.0368, grad_fn=<MeanBackward0>)\n",
      "Epoch:  399\n",
      "Loss:  tensor(0.0368, grad_fn=<MeanBackward0>)\n",
      "Epoch:  400\n",
      "Loss:  tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "Epoch:  401\n",
      "Loss:  tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "Epoch:  402\n",
      "Loss:  tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "Epoch:  403\n",
      "Loss:  tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "Epoch:  404\n",
      "Loss:  tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "Epoch:  405\n",
      "Loss:  tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "Epoch:  406\n",
      "Loss:  tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "Epoch:  407\n",
      "Loss:  tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "Epoch:  408\n",
      "Loss:  tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "Epoch:  409\n",
      "Loss:  tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "Epoch:  410\n",
      "Loss:  tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "Epoch:  411\n",
      "Loss:  tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "Epoch:  412\n",
      "Loss:  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "Epoch:  413\n",
      "Loss:  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "Epoch:  414\n",
      "Loss:  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "Epoch:  415\n",
      "Loss:  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "Epoch:  416\n",
      "Loss:  tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "Epoch:  417\n",
      "Loss:  tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "Epoch:  418\n",
      "Loss:  tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "Epoch:  419\n",
      "Loss:  tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "Epoch:  420\n",
      "Loss:  tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "Epoch:  421\n",
      "Loss:  tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "Epoch:  422\n",
      "Loss:  tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "Epoch:  423\n",
      "Loss:  tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "Epoch:  424\n",
      "Loss:  tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "Epoch:  425\n",
      "Loss:  tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "Epoch:  426\n",
      "Loss:  tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "Epoch:  427\n",
      "Loss:  tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "Epoch:  428\n",
      "Loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "Epoch:  429\n",
      "Loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "Epoch:  430\n",
      "Loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "Epoch:  431\n",
      "Loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "Epoch:  432\n",
      "Loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "Epoch:  433\n",
      "Loss:  tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "Epoch:  434\n",
      "Loss:  tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "Epoch:  435\n",
      "Loss:  tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "Epoch:  436\n",
      "Loss:  tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "Epoch:  437\n",
      "Loss:  tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "Epoch:  438\n",
      "Loss:  tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "Epoch:  439\n",
      "Loss:  tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "Epoch:  440\n",
      "Loss:  tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "Epoch:  441\n",
      "Loss:  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
      "Epoch:  442\n",
      "Loss:  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
      "Epoch:  443\n",
      "Loss:  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
      "Epoch:  444\n",
      "Loss:  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
      "Epoch:  445\n",
      "Loss:  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
      "Epoch:  446\n",
      "Loss:  tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "Epoch:  447\n",
      "Loss:  tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "Epoch:  448\n",
      "Loss:  tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "Epoch:  449\n",
      "Loss:  tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "Epoch:  450\n",
      "Loss:  tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "Epoch:  451\n",
      "Loss:  tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "Epoch:  452\n",
      "Loss:  tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "Epoch:  453\n",
      "Loss:  tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "Epoch:  454\n",
      "Loss:  tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "Epoch:  455\n",
      "Loss:  tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "Epoch:  456\n",
      "Loss:  tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "Epoch:  457\n",
      "Loss:  tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "Epoch:  458\n",
      "Loss:  tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "Epoch:  459\n",
      "Loss:  tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "Epoch:  460\n",
      "Loss:  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Epoch:  461\n",
      "Loss:  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Epoch:  462\n",
      "Loss:  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Epoch:  463\n",
      "Loss:  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Epoch:  464\n",
      "Loss:  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Epoch:  465\n",
      "Loss:  tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Epoch:  466\n",
      "Loss:  tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "Epoch:  467\n",
      "Loss:  tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "Epoch:  468\n",
      "Loss:  tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "Epoch:  469\n",
      "Loss:  tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "Epoch:  470\n",
      "Loss:  tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "Epoch:  471\n",
      "Loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "Epoch:  472\n",
      "Loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "Epoch:  473\n",
      "Loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "Epoch:  474\n",
      "Loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "Epoch:  475\n",
      "Loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "Epoch:  476\n",
      "Loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "Epoch:  477\n",
      "Loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "Epoch:  478\n",
      "Loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "Epoch:  479\n",
      "Loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "Epoch:  480\n",
      "Loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "Epoch:  481\n",
      "Loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch:  482\n",
      "Loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch:  483\n",
      "Loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch:  484\n",
      "Loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch:  485\n",
      "Loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch:  486\n",
      "Loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch:  487\n",
      "Loss:  tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "Epoch:  488\n",
      "Loss:  tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "Epoch:  489\n",
      "Loss:  tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "Epoch:  490\n",
      "Loss:  tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "Epoch:  491\n",
      "Loss:  tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "Epoch:  492\n",
      "Loss:  tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "Epoch:  493\n",
      "Loss:  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "Epoch:  494\n",
      "Loss:  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "Epoch:  495\n",
      "Loss:  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "Epoch:  496\n",
      "Loss:  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "Epoch:  497\n",
      "Loss:  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "Epoch:  498\n",
      "Loss:  tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "Epoch:  499\n",
      "Loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch:  500\n",
      "Loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch:  501\n",
      "Loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch:  502\n",
      "Loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch:  503\n",
      "Loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch:  504\n",
      "Loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch:  505\n",
      "Loss:  tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "Epoch:  506\n",
      "Loss:  tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "Epoch:  507\n",
      "Loss:  tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "Epoch:  508\n",
      "Loss:  tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "Epoch:  509\n",
      "Loss:  tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "Epoch:  510\n",
      "Loss:  tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "Epoch:  511\n",
      "Loss:  tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "Epoch:  512\n",
      "Loss:  tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "Epoch:  513\n",
      "Loss:  tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "Epoch:  514\n",
      "Loss:  tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "Epoch:  515\n",
      "Loss:  tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "Epoch:  516\n",
      "Loss:  tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "Epoch:  517\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  518\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  519\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  520\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  521\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  522\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  523\n",
      "Loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
      "Epoch:  524\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  525\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  526\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  527\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  528\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  529\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  530\n",
      "Loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "Epoch:  531\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  532\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  533\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  534\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  535\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  536\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  537\n",
      "Loss:  tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "Epoch:  538\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  539\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  540\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  541\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  542\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  543\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  544\n",
      "Loss:  tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "Epoch:  545\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  546\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  547\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  548\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  549\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  550\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  551\n",
      "Loss:  tensor(0.0339, grad_fn=<MeanBackward0>)\n",
      "Epoch:  552\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  553\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  554\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  555\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  556\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  557\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  558\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  559\n",
      "Loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "Epoch:  560\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  561\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  562\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  563\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  564\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  565\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  566\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  567\n",
      "Loss:  tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "Epoch:  568\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  569\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  570\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  571\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  572\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  573\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  574\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  575\n",
      "Loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch:  576\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  577\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  578\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  579\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  580\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  581\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  582\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  583\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  584\n",
      "Loss:  tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "Epoch:  585\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  586\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  587\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  588\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  589\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  590\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  591\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  592\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  593\n",
      "Loss:  tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "Epoch:  594\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  595\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  596\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  597\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  598\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  599\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  600\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  601\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  602\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  603\n",
      "Loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch:  604\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  605\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  606\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  607\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  608\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  609\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  610\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  611\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  612\n",
      "Loss:  tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "Epoch:  613\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  614\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  615\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  616\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  617\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  618\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  619\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  620\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  621\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  622\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  623\n",
      "Loss:  tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "Epoch:  624\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  625\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  626\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  627\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  628\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  629\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  630\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  631\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  632\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  633\n",
      "Loss:  tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "Epoch:  634\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  635\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  636\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  637\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  638\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  639\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  640\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  641\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  642\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  643\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  644\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  645\n",
      "Loss:  tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "Epoch:  646\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  647\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  648\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  649\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  650\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  651\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  652\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  653\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  654\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  655\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  656\n",
      "Loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "Epoch:  657\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  658\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  659\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  660\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  661\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  662\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  663\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  664\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  665\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  666\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  667\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  668\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  669\n",
      "Loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "Epoch:  670\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  671\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  672\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  673\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  674\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  675\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  676\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  677\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  678\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  679\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  680\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  681\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  682\n",
      "Loss:  tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "Epoch:  683\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  684\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  685\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  686\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  687\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  688\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  689\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  690\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  691\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  692\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  693\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  694\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  695\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  696\n",
      "Loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "Epoch:  697\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  698\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  699\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  700\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  701\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  702\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  703\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  704\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  705\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  706\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  707\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  708\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  709\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  710\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  711\n",
      "Loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "Epoch:  712\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  713\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  714\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  715\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  716\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  717\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  718\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  719\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  720\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  721\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  722\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  723\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  724\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  725\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  726\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  727\n",
      "Loss:  tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "Epoch:  728\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  729\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  730\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  731\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  732\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  733\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  734\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  735\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  736\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  737\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  738\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  739\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  740\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  741\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  742\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  743\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  744\n",
      "Loss:  tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "Epoch:  745\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  746\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  747\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  748\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  749\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  750\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  751\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  752\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  753\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  754\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  755\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  756\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  757\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  758\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  759\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  760\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  761\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  762\n",
      "Loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch:  763\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  764\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  765\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  766\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  767\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  768\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  769\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  770\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  771\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  772\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  773\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  774\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  775\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  776\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  777\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  778\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  779\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  780\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  781\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  782\n",
      "Loss:  tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "Epoch:  783\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  784\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  785\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  786\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  787\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  788\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  789\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  790\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  791\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  792\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  793\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  794\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  795\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  796\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  797\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  798\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  799\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  800\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  801\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  802\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  803\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  804\n",
      "Loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "Epoch:  805\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  806\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  807\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  808\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  809\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  810\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  811\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  812\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  813\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  814\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  815\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  816\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  817\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  818\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  819\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  820\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  821\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  822\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  823\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  824\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  825\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  826\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  827\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  828\n",
      "Loss:  tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "Epoch:  829\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  830\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  831\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  832\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  833\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  834\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  835\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  836\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  837\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  838\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  839\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  840\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  841\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  842\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  843\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  844\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  845\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  846\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  847\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  848\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  849\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  850\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  851\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  852\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  853\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  854\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  855\n",
      "Loss:  tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "Epoch:  856\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  857\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  858\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  859\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  860\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  861\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  862\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  863\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  864\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  865\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  866\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  867\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  868\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  869\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  870\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  871\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  872\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  873\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  874\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  875\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  876\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  877\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  878\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  879\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  880\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  881\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  882\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  883\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  884\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  885\n",
      "Loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "Epoch:  886\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  887\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  888\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  889\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  890\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  891\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  892\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  893\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  894\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  895\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  896\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  897\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  898\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  899\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  900\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  901\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  902\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  903\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  904\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  905\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  906\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  907\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  908\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  909\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  910\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  911\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  912\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  913\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  914\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  915\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  916\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  917\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  918\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  919\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  920\n",
      "Loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "Epoch:  921\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  922\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  923\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  924\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  925\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  926\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  927\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  928\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  929\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  930\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  931\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  932\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  933\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  934\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  935\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  936\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  937\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  938\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  939\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  940\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  941\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  942\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  943\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  944\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  945\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  946\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  947\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  948\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  949\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  950\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  951\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  952\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  953\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  954\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  955\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  956\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  957\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  958\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  959\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  960\n",
      "Loss:  tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "Epoch:  961\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  962\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  963\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  964\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  965\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  966\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  967\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  968\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  969\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  970\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  971\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  972\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  973\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  974\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  975\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  976\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  977\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  978\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  979\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  980\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  981\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  982\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  983\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  984\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  985\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  986\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  987\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  988\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  989\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  990\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  991\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  992\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  993\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  994\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  995\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  996\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  997\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  998\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  999\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1000\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1001\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1002\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1003\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1004\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1005\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1006\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1007\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1008\n",
      "Loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1009\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1010\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1011\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1012\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1013\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1014\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1015\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1016\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1017\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1018\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1019\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1020\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1021\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1022\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1023\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1024\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1025\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1026\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1027\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1028\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1029\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1030\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1031\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1032\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1033\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1034\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1035\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1036\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1037\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1038\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1039\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1040\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1041\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1042\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1043\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1044\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1045\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1046\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1047\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1048\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1049\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1050\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1051\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1052\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1053\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1054\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1055\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1056\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1057\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1058\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1059\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1060\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1061\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1062\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1063\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1064\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1065\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1066\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1067\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1068\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1069\n",
      "Loss:  tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1070\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1071\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1072\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1073\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1074\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1075\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1076\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1077\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1078\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1079\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1080\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1081\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1082\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1083\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1084\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1085\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1086\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1087\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1088\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1089\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1090\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1091\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1092\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1093\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1094\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1095\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1096\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1097\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1098\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1099\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1100\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1101\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1102\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1103\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1104\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1105\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1106\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1107\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1108\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1109\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1110\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1111\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1112\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1113\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1114\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1115\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1116\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1117\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1118\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1119\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1120\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1121\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1122\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1123\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1124\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1125\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1126\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1127\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1128\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1129\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1130\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1131\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1132\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1133\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1134\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1135\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1136\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1137\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1138\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1139\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1140\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1141\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1142\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1143\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1144\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1145\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1146\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1147\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1148\n",
      "Loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1149\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1150\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1151\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1152\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1153\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1154\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1155\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1156\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1157\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1158\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1159\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1160\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1161\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1162\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1163\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1164\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1165\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1166\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1167\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1168\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1169\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1170\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1171\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1172\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1173\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1174\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1175\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1176\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1177\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1178\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1179\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1180\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1181\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1182\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1183\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1184\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1185\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1186\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1187\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1188\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1189\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1190\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1191\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1192\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1193\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1194\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1195\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1196\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1197\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1198\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1199\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1200\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1201\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1202\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1203\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1204\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1205\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1206\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1207\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1208\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1209\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1210\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1211\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1212\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1213\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1214\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1215\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1216\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1217\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1218\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1219\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1220\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1221\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1222\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1223\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1224\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1225\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1226\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1227\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1228\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1229\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1230\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1231\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1232\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1233\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1234\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1235\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1236\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1237\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1238\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1239\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1240\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1241\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1242\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1243\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1244\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1245\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1246\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1247\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1248\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1249\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1250\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1251\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1252\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1253\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1254\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1255\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1256\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1257\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1258\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1259\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1260\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1261\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1262\n",
      "Loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1263\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1264\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1265\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1266\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1267\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1268\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1269\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1270\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1271\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1272\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1273\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1274\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1275\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1276\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1277\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1278\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1279\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1280\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1281\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1282\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1283\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1284\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1285\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1286\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1287\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1288\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1289\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1290\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1291\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1292\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1293\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1294\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1295\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1296\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1297\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1298\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1299\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1300\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1301\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1302\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1303\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1304\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1305\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1306\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1307\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1308\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1309\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1310\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1311\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1312\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1313\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1314\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1315\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1316\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1317\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1318\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1319\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1320\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1321\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1322\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1323\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1324\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1325\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1326\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1327\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1328\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1329\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1330\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1331\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1332\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1333\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1334\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1335\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1336\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1337\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1338\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1339\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1340\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1341\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1342\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1343\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1344\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1345\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1346\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1347\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1348\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1349\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1350\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1351\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1352\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1353\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1354\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1355\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1356\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1357\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1358\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1359\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1360\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1361\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1362\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1363\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1364\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1365\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1366\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1367\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1368\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1369\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1370\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1371\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1372\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1373\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1374\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1375\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1376\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1377\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1378\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1379\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1380\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1381\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1382\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1383\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1384\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1385\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1386\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1387\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1388\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1389\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1390\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1391\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1392\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1393\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1394\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1395\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1396\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1397\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1398\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1399\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1400\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1401\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1402\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1403\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1404\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1405\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1406\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1407\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1408\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1409\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1410\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1411\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1412\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1413\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1414\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1415\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1416\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1417\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1418\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1419\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1420\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1421\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1422\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1423\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1424\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1425\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1426\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1427\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1428\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1429\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1430\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1431\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1432\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1433\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1434\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1435\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1436\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1437\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1438\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1439\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1440\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1441\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1442\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1443\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1444\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1445\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1446\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1447\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1448\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1449\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1450\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1451\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1452\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1453\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1454\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1455\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1456\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1457\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1458\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1459\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1460\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1461\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1462\n",
      "Loss:  tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1463\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1464\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1465\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1466\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1467\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1468\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1469\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1470\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1471\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1472\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1473\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1474\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1475\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1476\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1477\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1478\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1479\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1480\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1481\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1482\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1483\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1484\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1485\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1486\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1487\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1488\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1489\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1490\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1491\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1492\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1493\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1494\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1495\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1496\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1497\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1498\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1499\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1500\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1501\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1502\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1503\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1504\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1505\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1506\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1507\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1508\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1509\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1510\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1511\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1512\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1513\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1514\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1515\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1516\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1517\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1518\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1519\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1520\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1521\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1522\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1523\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1524\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1525\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1526\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1527\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1528\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1529\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1530\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1531\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1532\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1533\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1534\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1535\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1536\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1537\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1538\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1539\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1540\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1541\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1542\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1543\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1544\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1545\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1546\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1547\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1548\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1549\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1550\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1551\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1552\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1553\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1554\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1555\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1556\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1557\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1558\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1559\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1560\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1561\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1562\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1563\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1564\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1565\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1566\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1567\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1568\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1569\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1570\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1571\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1572\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1573\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1574\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1575\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1576\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1577\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1578\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1579\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1580\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1581\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1582\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1583\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1584\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1585\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1586\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1587\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1588\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1589\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1590\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1591\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1592\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1593\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1594\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1595\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1596\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1597\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1598\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1599\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1600\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1601\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1602\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1603\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1604\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1605\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1606\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1607\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1608\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1609\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1610\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1611\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1612\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1613\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1614\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1615\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1616\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1617\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1618\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1619\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1620\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1621\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1622\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1623\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1624\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1625\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1626\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1627\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1628\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1629\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1630\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1631\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1632\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1633\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1634\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1635\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1636\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1637\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1638\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1639\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1640\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1641\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1642\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1643\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1644\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1645\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1646\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1647\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1648\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1649\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1650\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1651\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1652\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1653\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1654\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1655\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1656\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1657\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1658\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1659\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1660\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1661\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1662\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1663\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1664\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1665\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1666\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1667\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1668\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1669\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1670\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1671\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1672\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1673\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1674\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1675\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1676\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1677\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1678\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1679\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1680\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1681\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1682\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1683\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1684\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1685\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1686\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1687\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1688\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1689\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1690\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1691\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1692\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1693\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1694\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1695\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1696\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1697\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1698\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1699\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1700\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1701\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1702\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1703\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1704\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1705\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1706\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1707\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1708\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1709\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1710\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1711\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1712\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1713\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1714\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1715\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1716\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1717\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1718\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1719\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1720\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1721\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1722\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1723\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1724\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1725\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1726\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1727\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1728\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1729\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1730\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1731\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1732\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1733\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1734\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1735\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1736\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1737\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1738\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1739\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1740\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1741\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1742\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1743\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1744\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1745\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1746\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1747\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1748\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1749\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1750\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1751\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1752\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1753\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1754\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1755\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1756\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1757\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1758\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1759\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1760\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1761\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1762\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1763\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1764\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1765\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1766\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1767\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1768\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1769\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1770\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1771\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1772\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1773\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1774\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1775\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1776\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1777\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1778\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1779\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1780\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1781\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1782\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1783\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1784\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1785\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1786\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1787\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1788\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1789\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1790\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1791\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1792\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1793\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1794\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1795\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1796\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1797\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1798\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1799\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1800\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1801\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1802\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1803\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1804\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1805\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1806\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1807\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1808\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1809\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1810\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1811\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1812\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1813\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1814\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1815\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1816\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1817\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1818\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1819\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1820\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1821\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1822\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1823\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1824\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1825\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1826\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1827\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1828\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1829\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1830\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1831\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1832\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1833\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1834\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1835\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1836\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1837\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1838\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1839\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1840\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1841\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1842\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1843\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1844\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1845\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1846\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1847\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1848\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1849\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1850\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1851\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1852\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1853\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1854\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1855\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1856\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1857\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1858\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1859\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1860\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1861\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1862\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1863\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1864\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1865\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1866\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1867\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1868\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1869\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1870\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1871\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1872\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1873\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1874\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1875\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1876\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1877\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1878\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1879\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1880\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1881\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1882\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1883\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1884\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1885\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1886\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1887\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1888\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1889\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1890\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1891\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1892\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1893\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1894\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1895\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1896\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1897\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1898\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1899\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1900\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1901\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1902\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1903\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1904\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1905\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1906\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1907\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1908\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1909\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1910\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1911\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1912\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1913\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1914\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1915\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1916\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1917\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1918\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1919\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1920\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1921\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1922\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1923\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1924\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1925\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1926\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1927\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1928\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1929\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1930\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1931\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1932\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1933\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1934\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1935\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1936\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1937\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1938\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1939\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1940\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1941\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1942\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1943\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1944\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1945\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1946\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1947\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1948\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1949\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1950\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1951\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1952\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1953\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1954\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1955\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1956\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1957\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1958\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1959\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1960\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1961\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1962\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1963\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1964\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1965\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1966\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1967\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1968\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1969\n",
      "Loss:  tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1970\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1971\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1972\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1973\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1974\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1975\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1976\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1977\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1978\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1979\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1980\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1981\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1982\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1983\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1984\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1985\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1986\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1987\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1988\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1989\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1990\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1991\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1992\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1993\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1994\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1995\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1996\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1997\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1998\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  1999\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2000\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2001\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2002\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2003\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2004\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2005\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2006\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2007\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2008\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2009\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2010\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2011\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2012\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2013\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2014\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2015\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2016\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2017\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2018\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2019\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2020\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2021\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2022\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2023\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2024\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2025\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2026\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2027\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2028\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2029\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2030\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2031\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2032\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2033\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2034\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2035\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2036\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2037\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2038\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2039\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2040\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2041\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2042\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2043\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2044\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2045\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2046\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2047\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2048\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2049\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2050\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2051\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2052\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2053\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2054\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2055\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2056\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2057\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2058\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2059\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2060\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2061\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2062\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2063\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2064\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2065\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2066\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2067\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2068\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2069\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2070\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2071\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2072\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2073\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2074\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2075\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2076\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2077\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2078\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2079\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2080\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2081\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2082\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2083\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2084\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2085\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2086\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2087\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2088\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2089\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2090\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2091\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2092\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2093\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2094\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2095\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2096\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2097\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2098\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2099\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2100\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2101\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2102\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2103\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2104\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2105\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2106\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2107\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2108\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2109\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2110\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2111\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2112\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2113\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2114\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2115\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2116\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2117\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2118\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2119\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2120\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2121\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2122\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2123\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2124\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2125\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2126\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2127\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2128\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2129\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2130\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2131\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2132\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2133\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2134\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2135\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2136\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2137\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2138\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2139\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2140\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2141\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2142\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2143\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2144\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2145\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2146\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2147\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2148\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2149\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2150\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2151\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2152\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2153\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2154\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2155\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2156\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2157\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2158\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2159\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2160\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2161\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2162\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2163\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2164\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2165\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2166\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2167\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2168\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2169\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2170\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2171\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2172\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2173\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2174\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2175\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2176\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2177\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2178\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2179\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2180\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2181\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2182\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2183\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2184\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2185\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2186\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2187\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2188\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2189\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2190\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2191\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2192\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2193\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2194\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2195\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2196\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2197\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2198\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2199\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2200\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2201\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2202\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2203\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2204\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2205\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2206\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2207\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2208\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2209\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2210\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2211\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2212\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2213\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2214\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2215\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2216\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2217\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2218\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2219\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2220\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2221\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2222\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2223\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2224\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2225\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2226\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2227\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2228\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2229\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2230\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2231\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2232\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2233\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2234\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2235\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2236\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2237\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2238\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2239\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2240\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2241\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2242\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2243\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2244\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2245\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2246\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2247\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2248\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2249\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2250\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2251\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2252\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2253\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2254\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2255\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2256\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2257\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2258\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2259\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2260\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2261\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2262\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2263\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2264\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2265\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2266\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2267\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2268\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2269\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2270\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2271\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2272\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2273\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2274\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2275\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2276\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2277\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2278\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2279\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2280\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2281\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2282\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2283\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2284\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2285\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2286\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2287\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2288\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2289\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2290\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2291\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2292\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2293\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2294\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2295\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2296\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2297\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2298\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2299\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2300\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2301\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2302\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2303\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2304\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2305\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2306\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2307\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2308\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2309\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2310\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2311\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2312\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2313\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2314\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2315\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2316\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2317\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2318\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2319\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2320\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2321\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2322\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2323\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2324\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2325\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2326\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2327\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2328\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2329\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2330\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2331\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2332\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2333\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2334\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2335\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2336\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2337\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2338\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2339\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2340\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2341\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2342\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2343\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2344\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2345\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2346\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2347\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2348\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2349\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2350\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2351\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2352\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2353\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2354\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2355\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2356\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2357\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2358\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2359\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2360\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2361\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2362\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2363\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2364\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2365\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2366\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2367\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2368\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2369\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2370\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2371\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2372\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2373\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2374\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2375\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2376\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2377\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2378\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2379\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2380\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2381\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2382\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2383\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2384\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2385\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2386\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2387\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2388\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2389\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2390\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2391\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2392\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2393\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2394\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2395\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2396\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2397\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2398\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2399\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2400\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2401\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2402\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2403\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2404\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2405\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2406\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2407\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2408\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2409\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2410\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2411\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2412\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2413\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2414\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2415\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2416\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2417\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2418\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2419\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2420\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2421\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2422\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2423\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2424\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2425\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2426\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2427\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2428\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2429\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2430\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2431\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2432\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2433\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2434\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2435\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2436\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2437\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2438\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2439\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2440\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2441\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2442\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2443\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2444\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2445\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2446\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2447\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2448\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2449\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2450\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2451\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2452\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2453\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2454\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2455\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2456\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2457\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2458\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2459\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2460\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2461\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2462\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2463\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2464\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2465\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2466\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2467\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2468\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2469\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2470\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2471\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2472\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2473\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2474\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2475\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2476\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2477\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2478\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2479\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2480\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2481\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2482\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2483\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2484\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2485\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2486\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2487\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2488\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2489\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2490\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2491\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2492\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2493\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2494\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2495\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2496\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2497\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2498\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2499\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2500\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2501\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2502\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2503\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2504\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2505\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2506\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2507\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2508\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2509\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2510\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2511\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2512\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2513\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2514\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2515\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2516\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2517\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2518\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2519\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2520\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2521\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2522\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2523\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2524\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2525\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2526\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2527\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2528\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2529\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2530\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2531\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2532\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2533\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2534\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2535\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2536\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2537\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2538\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2539\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2540\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2541\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2542\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2543\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2544\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2545\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2546\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2547\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2548\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2549\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2550\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2551\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2552\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2553\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2554\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2555\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2556\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2557\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2558\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2559\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2560\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2561\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2562\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2563\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2564\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2565\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2566\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2567\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2568\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2569\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2570\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2571\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2572\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2573\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2574\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2575\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2576\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2577\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2578\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2579\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2580\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2581\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2582\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2583\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2584\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2585\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2586\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2587\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2588\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2589\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2590\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2591\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2592\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2593\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2594\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2595\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2596\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2597\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2598\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2599\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2600\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2601\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2602\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2603\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2604\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2605\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2606\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2607\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2608\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2609\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2610\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2611\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2612\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2613\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2614\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2615\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2616\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2617\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2618\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2619\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2620\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2621\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2622\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2623\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2624\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2625\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2626\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2627\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2628\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2629\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2630\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2631\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2632\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2633\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2634\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2635\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2636\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2637\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2638\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2639\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2640\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2641\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2642\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2643\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2644\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2645\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2646\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2647\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2648\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2649\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2650\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2651\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2652\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2653\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2654\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2655\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2656\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2657\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2658\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2659\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2660\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2661\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2662\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2663\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2664\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2665\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2666\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2667\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2668\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2669\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2670\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2671\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2672\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2673\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2674\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2675\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2676\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2677\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2678\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2679\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2680\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2681\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2682\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2683\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2684\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2685\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2686\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2687\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2688\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2689\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2690\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2691\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2692\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2693\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2694\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2695\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2696\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2697\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2698\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2699\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2700\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2701\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2702\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2703\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2704\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2705\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2706\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2707\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2708\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2709\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2710\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2711\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2712\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2713\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2714\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2715\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2716\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2717\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2718\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2719\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2720\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2721\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2722\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2723\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2724\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2725\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2726\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2727\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2728\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2729\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2730\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2731\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2732\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2733\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2734\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2735\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2736\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2737\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2738\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2739\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2740\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2741\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2742\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2743\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2744\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2745\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2746\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2747\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2748\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2749\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2750\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2751\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2752\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2753\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2754\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2755\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2756\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2757\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2758\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2759\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2760\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2761\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2762\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2763\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2764\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2765\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2766\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2767\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2768\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2769\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2770\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2771\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2772\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2773\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2774\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2775\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2776\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2777\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2778\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2779\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2780\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2781\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2782\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2783\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2784\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2785\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2786\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2787\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2788\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2789\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2790\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2791\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2792\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2793\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2794\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2795\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2796\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2797\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2798\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2799\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2800\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2801\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2802\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2803\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2804\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2805\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2806\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2807\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2808\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2809\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2810\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2811\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2812\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2813\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2814\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2815\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2816\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2817\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2818\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2819\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2820\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2821\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2822\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2823\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2824\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2825\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2826\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2827\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2828\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2829\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2830\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2831\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2832\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2833\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2834\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2835\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2836\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2837\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2838\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2839\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2840\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2841\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2842\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2843\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2844\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2845\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2846\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2847\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2848\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2849\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2850\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2851\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2852\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2853\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2854\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2855\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2856\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2857\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2858\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2859\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2860\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2861\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2862\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2863\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2864\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2865\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2866\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2867\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2868\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2869\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2870\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2871\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2872\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2873\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2874\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2875\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2876\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2877\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2878\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2879\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2880\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2881\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2882\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2883\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2884\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2885\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2886\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2887\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2888\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2889\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2890\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2891\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2892\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2893\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2894\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2895\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2896\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2897\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2898\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2899\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2900\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2901\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2902\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2903\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2904\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2905\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2906\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2907\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2908\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2909\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2910\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2911\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2912\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2913\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2914\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2915\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2916\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2917\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2918\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2919\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2920\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2921\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2922\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2923\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2924\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2925\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2926\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2927\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2928\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2929\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2930\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2931\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2932\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2933\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2934\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2935\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2936\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2937\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2938\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2939\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2940\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2941\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2942\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2943\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2944\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2945\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2946\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2947\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2948\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2949\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2950\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2951\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2952\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2953\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2954\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2955\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2956\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2957\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2958\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2959\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2960\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2961\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2962\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2963\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2964\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2965\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2966\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2967\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2968\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2969\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2970\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2971\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2972\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2973\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2974\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2975\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2976\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2977\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2978\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2979\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2980\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2981\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2982\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2983\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2984\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2985\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2986\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2987\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2988\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2989\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2990\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2991\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2992\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2993\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2994\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2995\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2996\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2997\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2998\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  2999\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3000\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3001\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3002\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3003\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3004\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3005\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3006\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3007\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3008\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3009\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3010\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3011\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3012\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3013\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3014\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3015\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3016\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3017\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3018\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3019\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3020\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3021\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3022\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3023\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3024\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3025\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3026\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3027\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3028\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3029\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3030\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3031\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3032\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3033\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3034\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3035\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3036\n",
      "Loss:  tensor(0.0307, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3037\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3038\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3039\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3040\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3041\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3042\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3043\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3044\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3045\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3046\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3047\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3048\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3049\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3050\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3051\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3052\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3053\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3054\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3055\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3056\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3057\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3058\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3059\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3060\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3061\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3062\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3063\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3064\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3065\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3066\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3067\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3068\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3069\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3070\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3071\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3072\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3073\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3074\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3075\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3076\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3077\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3078\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3079\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3080\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3081\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3082\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3083\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3084\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3085\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3086\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3087\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3088\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3089\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3090\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3091\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3092\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3093\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3094\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3095\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3096\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3097\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3098\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3099\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3100\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3101\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3102\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3103\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3104\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3105\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3106\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3107\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3108\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3109\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3110\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3111\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3112\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3113\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3114\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3115\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3116\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3117\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3118\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3119\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3120\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3121\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3122\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3123\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3124\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3125\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3126\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3127\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3128\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3129\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3130\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3131\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3132\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3133\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3134\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3135\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3136\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3137\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3138\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3139\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3140\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3141\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3142\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3143\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3144\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3145\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3146\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3147\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3148\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3149\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3150\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3151\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3152\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3153\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3154\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3155\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3156\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3157\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3158\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3159\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3160\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3161\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3162\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3163\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3164\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3165\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3166\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3167\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3168\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3169\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3170\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3171\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3172\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3173\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3174\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3175\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3176\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3177\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3178\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3179\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3180\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3181\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3182\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3183\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3184\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3185\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3186\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3187\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3188\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3189\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3190\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3191\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3192\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3193\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3194\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3195\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3196\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3197\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3198\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3199\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3200\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3201\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3202\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3203\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3204\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3205\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3206\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3207\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3208\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3209\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3210\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3211\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3212\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3213\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3214\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3215\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3216\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3217\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3218\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3219\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3220\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3221\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3222\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3223\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3224\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3225\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3226\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3227\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3228\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3229\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3230\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3231\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3232\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3233\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3234\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3235\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3236\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3237\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3238\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3239\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3240\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3241\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3242\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3243\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3244\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3245\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3246\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3247\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3248\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3249\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3250\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3251\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3252\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3253\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3254\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3255\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3256\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3257\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3258\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3259\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3260\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3261\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3262\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3263\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3264\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3265\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3266\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3267\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3268\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3269\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3270\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3271\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3272\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3273\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3274\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3275\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3276\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3277\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3278\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3279\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3280\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3281\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3282\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3283\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3284\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3285\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3286\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3287\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3288\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3289\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3290\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3291\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3292\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3293\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3294\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3295\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3296\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3297\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3298\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3299\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3300\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3301\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3302\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3303\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3304\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3305\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3306\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3307\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3308\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3309\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3310\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3311\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3312\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3313\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3314\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3315\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3316\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3317\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3318\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3319\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3320\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3321\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3322\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3323\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3324\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3325\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3326\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3327\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3328\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3329\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3330\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3331\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3332\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3333\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3334\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3335\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3336\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3337\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3338\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3339\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3340\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3341\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3342\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3343\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3344\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3345\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3346\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3347\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3348\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3349\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3350\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3351\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3352\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3353\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3354\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3355\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3356\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3357\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3358\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3359\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3360\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3361\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3362\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3363\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3364\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3365\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3366\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3367\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3368\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3369\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3370\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3371\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3372\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3373\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3374\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3375\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3376\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3377\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3378\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3379\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3380\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3381\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3382\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3383\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3384\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3385\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3386\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3387\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3388\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3389\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3390\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3391\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3392\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3393\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3394\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3395\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3396\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3397\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3398\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3399\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3400\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3401\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3402\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3403\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3404\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3405\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3406\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3407\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3408\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3409\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3410\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3411\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3412\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3413\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3414\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3415\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3416\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3417\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3418\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3419\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3420\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3421\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3422\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3423\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3424\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3425\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3426\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3427\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3428\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3429\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3430\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3431\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3432\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3433\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3434\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3435\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3436\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3437\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3438\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3439\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3440\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3441\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3442\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3443\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3444\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3445\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3446\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3447\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3448\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3449\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3450\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3451\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3452\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3453\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3454\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3455\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3456\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3457\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3458\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3459\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3460\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3461\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3462\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3463\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3464\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3465\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3466\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3467\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3468\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3469\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3470\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3471\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3472\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3473\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3474\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3475\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3476\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3477\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3478\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3479\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3480\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3481\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3482\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3483\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3484\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3485\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3486\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3487\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3488\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3489\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3490\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3491\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3492\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3493\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3494\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3495\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3496\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3497\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3498\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3499\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3500\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3501\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3502\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3503\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3504\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3505\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3506\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3507\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3508\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3509\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3510\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3511\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3512\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3513\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3514\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3515\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3516\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3517\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3518\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3519\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3520\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3521\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3522\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3523\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3524\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3525\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3526\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3527\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3528\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3529\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3530\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3531\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3532\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3533\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3534\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3535\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3536\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3537\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3538\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3539\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3540\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3541\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3542\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3543\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3544\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3545\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3546\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3547\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3548\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3549\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3550\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3551\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3552\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3553\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3554\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3555\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3556\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3557\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3558\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3559\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3560\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3561\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3562\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3563\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3564\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3565\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3566\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3567\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3568\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3569\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3570\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3571\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3572\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3573\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3574\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3575\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3576\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3577\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3578\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3579\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3580\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3581\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3582\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3583\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3584\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3585\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3586\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3587\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3588\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3589\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3590\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3591\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3592\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3593\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3594\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3595\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3596\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3597\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3598\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3599\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3600\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3601\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3602\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3603\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3604\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3605\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3606\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3607\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3608\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3609\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3610\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3611\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3612\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3613\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3614\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3615\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3616\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3617\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3618\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3619\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3620\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3621\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3622\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3623\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3624\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3625\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3626\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3627\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3628\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3629\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3630\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3631\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3632\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3633\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3634\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3635\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3636\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3637\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3638\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3639\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3640\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3641\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3642\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3643\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3644\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3645\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3646\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3647\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3648\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3649\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3650\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3651\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3652\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3653\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3654\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3655\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3656\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3657\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3658\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3659\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3660\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3661\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3662\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3663\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3664\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3665\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3666\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3667\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3668\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3669\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3670\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3671\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3672\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3673\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3674\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3675\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3676\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3677\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3678\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3679\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3680\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3681\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3682\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3683\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3684\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3685\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3686\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3687\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3688\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3689\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3690\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3691\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3692\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3693\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3694\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3695\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3696\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3697\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3698\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3699\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3700\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3701\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3702\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3703\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3704\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3705\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3706\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3707\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3708\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3709\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3710\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3711\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3712\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3713\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3714\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3715\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3716\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3717\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3718\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3719\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3720\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3721\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3722\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3723\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3724\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3725\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3726\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3727\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3728\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3729\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3730\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3731\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3732\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3733\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3734\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3735\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3736\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3737\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3738\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3739\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3740\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3741\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3742\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3743\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3744\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3745\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3746\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3747\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3748\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3749\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3750\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3751\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3752\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3753\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3754\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3755\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3756\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3757\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3758\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3759\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3760\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3761\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3762\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3763\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3764\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3765\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3766\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3767\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3768\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3769\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3770\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3771\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3772\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3773\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3774\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3775\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3776\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3777\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3778\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3779\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3780\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3781\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3782\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3783\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3784\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3785\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3786\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3787\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3788\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3789\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3790\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3791\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3792\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3793\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3794\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3795\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3796\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3797\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3798\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3799\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3800\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3801\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3802\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3803\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3804\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3805\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3806\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3807\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3808\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3809\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3810\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3811\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3812\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3813\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3814\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3815\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3816\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3817\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3818\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3819\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3820\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3821\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3822\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3823\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3824\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3825\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3826\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3827\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3828\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3829\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3830\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3831\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3832\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3833\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3834\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3835\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3836\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3837\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3838\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3839\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3840\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3841\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3842\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3843\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3844\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3845\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3846\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3847\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3848\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3849\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3850\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3851\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3852\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3853\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3854\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3855\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3856\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3857\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3858\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3859\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3860\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3861\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3862\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3863\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3864\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3865\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3866\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3867\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3868\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3869\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3870\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3871\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3872\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3873\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3874\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3875\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3876\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3877\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3878\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3879\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3880\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3881\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3882\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3883\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3884\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3885\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3886\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3887\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3888\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3889\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3890\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3891\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3892\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3893\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3894\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3895\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3896\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3897\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3898\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3899\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3900\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3901\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3902\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3903\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3904\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3905\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3906\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3907\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3908\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3909\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3910\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3911\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3912\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3913\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3914\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3915\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3916\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3917\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3918\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3919\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3920\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3921\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3922\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3923\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3924\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3925\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3926\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3927\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3928\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3929\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3930\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3931\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3932\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3933\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3934\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3935\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3936\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3937\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3938\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3939\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3940\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3941\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3942\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3943\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3944\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3945\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3946\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3947\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3948\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3949\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3950\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3951\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3952\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3953\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3954\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3955\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3956\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3957\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3958\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3959\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3960\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3961\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3962\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3963\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3964\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3965\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3966\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3967\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3968\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3969\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3970\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3971\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3972\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3973\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3974\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3975\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3976\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3977\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3978\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3979\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3980\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3981\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3982\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3983\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3984\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3985\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3986\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3987\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3988\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3989\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3990\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3991\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3992\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3993\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3994\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3995\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3996\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3997\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3998\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  3999\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4000\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4001\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4002\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4003\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4004\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4005\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4006\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4007\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4008\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4009\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4010\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4011\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4012\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4013\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4014\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4015\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4016\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4017\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4018\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4019\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4020\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4021\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4022\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4023\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4024\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4025\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4026\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4027\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4028\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4029\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4030\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4031\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4032\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4033\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4034\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4035\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4036\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4037\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4038\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4039\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4040\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4041\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4042\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4043\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4044\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4045\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4046\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4047\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4048\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4049\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4050\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4051\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4052\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4053\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4054\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4055\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4056\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4057\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4058\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4059\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4060\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4061\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4062\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4063\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4064\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4065\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4066\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4067\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4068\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4069\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4070\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4071\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4072\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4073\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4074\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4075\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4076\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4077\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4078\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4079\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4080\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4081\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4082\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4083\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4084\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4085\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4086\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4087\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4088\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4089\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4090\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4091\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4092\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4093\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4094\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4095\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4096\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4097\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4098\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4099\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4100\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4101\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4102\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4103\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4104\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4105\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4106\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4107\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4108\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4109\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4110\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4111\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4112\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4113\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4114\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4115\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4116\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4117\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4118\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4119\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4120\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4121\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4122\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4123\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4124\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4125\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4126\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4127\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4128\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4129\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4130\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4131\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4132\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4133\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4134\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4135\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4136\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4137\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4138\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4139\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4140\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4141\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4142\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4143\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4144\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4145\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4146\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4147\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4148\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4149\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4150\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4151\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4152\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4153\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4154\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4155\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4156\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4157\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4158\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4159\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4160\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4161\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4162\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4163\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4164\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4165\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4166\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4167\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4168\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4169\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4170\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4171\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4172\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4173\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4174\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4175\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4176\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4177\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4178\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4179\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4180\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4181\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4182\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4183\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4184\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4185\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4186\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4187\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4188\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4189\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4190\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4191\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4192\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4193\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4194\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4195\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4196\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4197\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4198\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4199\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4200\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4201\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4202\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4203\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4204\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4205\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4206\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4207\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4208\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4209\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4210\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4211\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4212\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4213\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4214\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4215\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4216\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4217\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4218\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4219\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4220\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4221\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4222\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4223\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4224\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4225\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4226\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4227\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4228\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4229\n",
      "Loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4230\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4231\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4232\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4233\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4234\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4235\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4236\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4237\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4238\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4239\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4240\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4241\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4242\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4243\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4244\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4245\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4246\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4247\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4248\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4249\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4250\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4251\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4252\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4253\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4254\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4255\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4256\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4257\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4258\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4259\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4260\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4261\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4262\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4263\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4264\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4265\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4266\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4267\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4268\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4269\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4270\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4271\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4272\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4273\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4274\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4275\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4276\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4277\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4278\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4279\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4280\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4281\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4282\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4283\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4284\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4285\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4286\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4287\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4288\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4289\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4290\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4291\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4292\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4293\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4294\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4295\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4296\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4297\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4298\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4299\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4300\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4301\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4302\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4303\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4304\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4305\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4306\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4307\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4308\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4309\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4310\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4311\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4312\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4313\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4314\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4315\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4316\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4317\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4318\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4319\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4320\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4321\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4322\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4323\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4324\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4325\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4326\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4327\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4328\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4329\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4330\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4331\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4332\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4333\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4334\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4335\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4336\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4337\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4338\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4339\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4340\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4341\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4342\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4343\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4344\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4345\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4346\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4347\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4348\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4349\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4350\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4351\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4352\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4353\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4354\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4355\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4356\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4357\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4358\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4359\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4360\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4361\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4362\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4363\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4364\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4365\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4366\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4367\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4368\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4369\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4370\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4371\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4372\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4373\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4374\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4375\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4376\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4377\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4378\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4379\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4380\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4381\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4382\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4383\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4384\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4385\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4386\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4387\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4388\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4389\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4390\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4391\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4392\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4393\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4394\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4395\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4396\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4397\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4398\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4399\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4400\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4401\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4402\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4403\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4404\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4405\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4406\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4407\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4408\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4409\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4410\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4411\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4412\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4413\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4414\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4415\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4416\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4417\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4418\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4419\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4420\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4421\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4422\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4423\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4424\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4425\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4426\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4427\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4428\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4429\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4430\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4431\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4432\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4433\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4434\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4435\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4436\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4437\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4438\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4439\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4440\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4441\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4442\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4443\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4444\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4445\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4446\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4447\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4448\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4449\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4450\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4451\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4452\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4453\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4454\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4455\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4456\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4457\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4458\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4459\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4460\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4461\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4462\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4463\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4464\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4465\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4466\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4467\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4468\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4469\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4470\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4471\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4472\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4473\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4474\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4475\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4476\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4477\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4478\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4479\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4480\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4481\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4482\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4483\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4484\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4485\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4486\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4487\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4488\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4489\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4490\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4491\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4492\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4493\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4494\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4495\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4496\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4497\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4498\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4499\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4500\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4501\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4502\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4503\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4504\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4505\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4506\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4507\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4508\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4509\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4510\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4511\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4512\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4513\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4514\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4515\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4516\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4517\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4518\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4519\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4520\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4521\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4522\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4523\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4524\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4525\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4526\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4527\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4528\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4529\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4530\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4531\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4532\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4533\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4534\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4535\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4536\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4537\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4538\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4539\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4540\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4541\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4542\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4543\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4544\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4545\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4546\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4547\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4548\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4549\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4550\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4551\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4552\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4553\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4554\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4555\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4556\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4557\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4558\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4559\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4560\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4561\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4562\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4563\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4564\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4565\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4566\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4567\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4568\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4569\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4570\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4571\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4572\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4573\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4574\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4575\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4576\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4577\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4578\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4579\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4580\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4581\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4582\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4583\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4584\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4585\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4586\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4587\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4588\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4589\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4590\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4591\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4592\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4593\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4594\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4595\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4596\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4597\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4598\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4599\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4600\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4601\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4602\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4603\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4604\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4605\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4606\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4607\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4608\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4609\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4610\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4611\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4612\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4613\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4614\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4615\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4616\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4617\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4618\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4619\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4620\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4621\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4622\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4623\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4624\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4625\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4626\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4627\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4628\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4629\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4630\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4631\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4632\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4633\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4634\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4635\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4636\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4637\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4638\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4639\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4640\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4641\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4642\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4643\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4644\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4645\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4646\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4647\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4648\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4649\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4650\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4651\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4652\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4653\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4654\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4655\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4656\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4657\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4658\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4659\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4660\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4661\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4662\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4663\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4664\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4665\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4666\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4667\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4668\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4669\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4670\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4671\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4672\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4673\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4674\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4675\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4676\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4677\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4678\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4679\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4680\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4681\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4682\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4683\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4684\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4685\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4686\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4687\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4688\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4689\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4690\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4691\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4692\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4693\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4694\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4695\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4696\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4697\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4698\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4699\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4700\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4701\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4702\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4703\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4704\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4705\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4706\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4707\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4708\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4709\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4710\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4711\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4712\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4713\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4714\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4715\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4716\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4717\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4718\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4719\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4720\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4721\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4722\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4723\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4724\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4725\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4726\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4727\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4728\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4729\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4730\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4731\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4732\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4733\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4734\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4735\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4736\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4737\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4738\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4739\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4740\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4741\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4742\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4743\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4744\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4745\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4746\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4747\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4748\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4749\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4750\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4751\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4752\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4753\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4754\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4755\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4756\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4757\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4758\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4759\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4760\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4761\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4762\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4763\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4764\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4765\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4766\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4767\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4768\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4769\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4770\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4771\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4772\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4773\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4774\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4775\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4776\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4777\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4778\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4779\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4780\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4781\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4782\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4783\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4784\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4785\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4786\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4787\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4788\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4789\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4790\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4791\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4792\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4793\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4794\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4795\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4796\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4797\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4798\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4799\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4800\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4801\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4802\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4803\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4804\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4805\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4806\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4807\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4808\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4809\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4810\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4811\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4812\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4813\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4814\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4815\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4816\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4817\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4818\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4819\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4820\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4821\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4822\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4823\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4824\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4825\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4826\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4827\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4828\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4829\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4830\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4831\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4832\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4833\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4834\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4835\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4836\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4837\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4838\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4839\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4840\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4841\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4842\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4843\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4844\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4845\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4846\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4847\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4848\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4849\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4850\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4851\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4852\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4853\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4854\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4855\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4856\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4857\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4858\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4859\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4860\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4861\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4862\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4863\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4864\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4865\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4866\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4867\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4868\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4869\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4870\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4871\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4872\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4873\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4874\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4875\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4876\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4877\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4878\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4879\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4880\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4881\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4882\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4883\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4884\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4885\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4886\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4887\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4888\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4889\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4890\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4891\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4892\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4893\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4894\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4895\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4896\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4897\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4898\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4899\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4900\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4901\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4902\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4903\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4904\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4905\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4906\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4907\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4908\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4909\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4910\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4911\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4912\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4913\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4914\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4915\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4916\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4917\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4918\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4919\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4920\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4921\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4922\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4923\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4924\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4925\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4926\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4927\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4928\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4929\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4930\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4931\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4932\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4933\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4934\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4935\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4936\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4937\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4938\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4939\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4940\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4941\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4942\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4943\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4944\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4945\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4946\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4947\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4948\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4949\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4950\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4951\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4952\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4953\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4954\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4955\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4956\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4957\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4958\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4959\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4960\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4961\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4962\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4963\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4964\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4965\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4966\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4967\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4968\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4969\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4970\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4971\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4972\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4973\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4974\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4975\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4976\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4977\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4978\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4979\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4980\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4981\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4982\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4983\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4984\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4985\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4986\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4987\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4988\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4989\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4990\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4991\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4992\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4993\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4994\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4995\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4996\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4997\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4998\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "Epoch:  4999\n",
      "Loss:  tensor(0.0305, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    print(\"Epoch: \",i)\n",
    "    ytrain = Model(xtrain)\n",
    "    loss = lossfunc(ytrue,ytrain)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    print('Loss: ',loss)\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = Model(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6b7300cd50>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xtrain,ytrain.reshape([-1]).detach().numpy())\n",
    "plt.plot(x,y,'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[-0.1361],\n",
       "                      [ 0.3083],\n",
       "                      [ 0.4897],\n",
       "                      [-0.5441],\n",
       "                      [ 0.8942]])),\n",
       "             ('0.bias', tensor([ 0.0544,  0.1634, -0.2684, -0.3606,  0.3977])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.2230,  0.0109,  0.1064, -0.0355,  0.0428]])),\n",
       "             ('2.bias', tensor([-0.1443]))])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparison of LGPT Bayesian and Frequentist Models')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "\n",
    "plt.plot(xt,yt.reshape([-1]).detach().numpy(), 'r' ,label = 'Bayesian LGPT')\n",
    "plt.plot(xtrain,ytrain.reshape([-1]).detach().numpy(), 'g', label = 'Frequentist')\n",
    "plt.plot(x,y,'bo', label = 'True', alpha = 0.2)\n",
    "plt.ylim([-0.2,1.4])\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of LGPT Bayesian and Frequentist Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequentist Model seems to ignore the central peak while try to accomodate the other small peaks, whereas, the model trained with LGPT indicates that it tries to accomodate for all type of peaks, including the central one, and for the others, the LGPT one tries to predict the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that this may change with your method of Aggregating the Weights, one might also take samples from all the chains after *Burn-In* period to approximate the weights posterior distribution, something that I've not done here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
